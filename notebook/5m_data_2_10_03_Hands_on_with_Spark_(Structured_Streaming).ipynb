{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAlbfpGF5aUh"
      },
      "source": [
        "# Hands-on with Spark (Structured Streaming)\n",
        "\n",
        "![spark](https://cdn-images-1.medium.com/max/300/1*c8CtvqKJDVUnMoPGujF5fA.png)\n",
        "\n",
        "In the previous lesson, we learnt about Spark SQL, Dataframes and Pandas API. In this lesson, we will continue with the Structured Streaming.\n",
        "\n",
        "Structured Streaming is a scalable and fault-tolerant stream processing engine built on the Spark SQL engine. You can express your streaming computation the same way you would express a batch computation on static data. The Spark SQL engine will take care of running it incrementally and continuously and updating the final result as streaming data continues to arrive.\n",
        "\n",
        "You can use the Dataset/DataFrame API to express streaming aggregations, event-time windows, stream-to-batch joins, etc. The computation is executed on the same optimized Spark SQL engine. Finally, the system ensures end-to-end exactly-once fault-tolerance guarantees through checkpointing and Write-Ahead Logs. In short, Structured Streaming provides **fast, scalable, fault-tolerant, end-to-end exactly-once** stream processing without the user having to reason about streaming.\n",
        "\n",
        "Internally, by default, Structured Streaming queries are processed using a micro-batch processing engine, which processes data streams as a series of small batch jobs thereby achieving end-to-end latencies as low as 100 milliseconds and exactly-once fault-tolerance guarantees."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0M79JSa6Oqv"
      },
      "source": [
        "## Installing and Initializing Spark\n",
        "\n",
        "First, like previously, we'll need to install Spark and its dependencies:\n",
        "\n",
        "1.   Java 8\n",
        "2.   Apache Spark with Hadoop\n",
        "3.   Findspark (used to locate the Spark in the system)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KE17krsq6Rd6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "# os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.0-bin-hadoop3\"\n",
        "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0 pyspark-shell'\n",
        "\n",
        "# set the options to connect to our Kafka cluster\n",
        "options = {\n",
        "    # \"kafka.sasl.jaas.config\": 'org.apache.kafka.common.security.scram.ScramLoginModule required username=\"YnJhdmUtZmlzaC0xMTQ2MyQSvwXBuLOQsV1W7YffuC8cDaZcA3fKQwakMhnQGgg\" password=\"MDUxNjc4YzEtYzYxNy00NTE1LWEwNWYtMDBhODRlZmE0OGJm\";',\n",
        "    # \"kafka.sasl.mechanism\": \"SCRAM-SHA-256\",\n",
        "    # \"kafka.security.protocol\" : \"SASL_SSL\",\n",
        "    \"kafka.bootstrap.servers\": 'localhost:9092',\n",
        "    \"subscribe\": 'pizza-orders',\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ra8Ncwms6UsD"
      },
      "outputs": [],
      "source": [
        "# # findspark is only required if you are using a standalone Spark installation (downloaded tar.gz)\n",
        "# import findspark\n",
        "# findspark.init()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The below cell may take a few minutes to run. It is slow because:\n",
        "- Package downloading: Your PYSPARK_SUBMIT_ARGS includes a Kafka package that needs to be downloaded from Maven repositories on first run\n",
        "- JVM cold start: Initial JVM startup is always slow\n",
        "- Jupyter overhead: Running in a notebook adds some initialization overhead"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhi1xuPB6VfD"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ":: loading settings :: url = jar:file:/opt/homebrew/Caskroom/miniconda/base/envs/kafka/lib/python3.10/site-packages/pyspark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Ivy Default Cache set to: /Users/germayne/.ivy2/cache\n",
            "The jars for the packages stored in: /Users/germayne/.ivy2/jars\n",
            "org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency\n",
            ":: resolving dependencies :: org.apache.spark#spark-submit-parent-e6aab70d-b453-41bd-8361-ba03fcce1386;1.0\n",
            "\tconfs: [default]\n",
            "\tfound org.apache.spark#spark-sql-kafka-0-10_2.12;3.5.0 in central\n",
            "\tfound org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.0 in central\n",
            "\tfound org.apache.kafka#kafka-clients;3.4.1 in central\n",
            "\tfound org.lz4#lz4-java;1.8.0 in central\n",
            "\tfound org.xerial.snappy#snappy-java;1.1.10.3 in central\n",
            "\tfound org.slf4j#slf4j-api;2.0.7 in central\n",
            "\tfound org.apache.hadoop#hadoop-client-runtime;3.3.4 in central\n",
            "\tfound org.apache.hadoop#hadoop-client-api;3.3.4 in central\n",
            "\tfound commons-logging#commons-logging;1.1.3 in central\n",
            "\tfound com.google.code.findbugs#jsr305;3.0.0 in central\n",
            "\tfound org.apache.commons#commons-pool2;2.11.1 in central\n",
            "downloading https://repo1.maven.org/maven2/org/apache/spark/spark-sql-kafka-0-10_2.12/3.5.0/spark-sql-kafka-0-10_2.12-3.5.0.jar ...\n",
            "\t[SUCCESSFUL ] org.apache.spark#spark-sql-kafka-0-10_2.12;3.5.0!spark-sql-kafka-0-10_2.12.jar (572ms)\n",
            "downloading https://repo1.maven.org/maven2/org/apache/spark/spark-token-provider-kafka-0-10_2.12/3.5.0/spark-token-provider-kafka-0-10_2.12-3.5.0.jar ...\n",
            "\t[SUCCESSFUL ] org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.0!spark-token-provider-kafka-0-10_2.12.jar (343ms)\n",
            "downloading https://repo1.maven.org/maven2/org/apache/kafka/kafka-clients/3.4.1/kafka-clients-3.4.1.jar ...\n",
            "\t[SUCCESSFUL ] org.apache.kafka#kafka-clients;3.4.1!kafka-clients.jar (902ms)\n",
            "downloading https://repo1.maven.org/maven2/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar ...\n",
            "\t[SUCCESSFUL ] com.google.code.findbugs#jsr305;3.0.0!jsr305.jar (340ms)\n",
            "downloading https://repo1.maven.org/maven2/org/apache/commons/commons-pool2/2.11.1/commons-pool2-2.11.1.jar ...\n",
            "\t[SUCCESSFUL ] org.apache.commons#commons-pool2;2.11.1!commons-pool2.jar (341ms)\n",
            "downloading https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-client-runtime/3.3.4/hadoop-client-runtime-3.3.4.jar ...\n",
            "\t[SUCCESSFUL ] org.apache.hadoop#hadoop-client-runtime;3.3.4!hadoop-client-runtime.jar (1544ms)\n",
            "downloading https://repo1.maven.org/maven2/org/lz4/lz4-java/1.8.0/lz4-java-1.8.0.jar ...\n",
            "\t[SUCCESSFUL ] org.lz4#lz4-java;1.8.0!lz4-java.jar (348ms)\n",
            "downloading https://repo1.maven.org/maven2/org/xerial/snappy/snappy-java/1.1.10.3/snappy-java-1.1.10.3.jar ...\n",
            "\t[SUCCESSFUL ] org.xerial.snappy#snappy-java;1.1.10.3!snappy-java.jar(bundle) (376ms)\n",
            "downloading https://repo1.maven.org/maven2/org/slf4j/slf4j-api/2.0.7/slf4j-api-2.0.7.jar ...\n",
            "\t[SUCCESSFUL ] org.slf4j#slf4j-api;2.0.7!slf4j-api.jar (335ms)\n",
            "downloading https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-client-api/3.3.4/hadoop-client-api-3.3.4.jar ...\n",
            "\t[SUCCESSFUL ] org.apache.hadoop#hadoop-client-api;3.3.4!hadoop-client-api.jar (1112ms)\n",
            "downloading https://repo1.maven.org/maven2/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar ...\n",
            "\t[SUCCESSFUL ] commons-logging#commons-logging;1.1.3!commons-logging.jar (337ms)\n",
            ":: resolution report :: resolve 15617ms :: artifacts dl 6564ms\n",
            "\t:: modules in use:\n",
            "\tcom.google.code.findbugs#jsr305;3.0.0 from central in [default]\n",
            "\tcommons-logging#commons-logging;1.1.3 from central in [default]\n",
            "\torg.apache.commons#commons-pool2;2.11.1 from central in [default]\n",
            "\torg.apache.hadoop#hadoop-client-api;3.3.4 from central in [default]\n",
            "\torg.apache.hadoop#hadoop-client-runtime;3.3.4 from central in [default]\n",
            "\torg.apache.kafka#kafka-clients;3.4.1 from central in [default]\n",
            "\torg.apache.spark#spark-sql-kafka-0-10_2.12;3.5.0 from central in [default]\n",
            "\torg.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.0 from central in [default]\n",
            "\torg.lz4#lz4-java;1.8.0 from central in [default]\n",
            "\torg.slf4j#slf4j-api;2.0.7 from central in [default]\n",
            "\torg.xerial.snappy#snappy-java;1.1.10.3 from central in [default]\n",
            "\t---------------------------------------------------------------------\n",
            "\t|                  |            modules            ||   artifacts   |\n",
            "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
            "\t---------------------------------------------------------------------\n",
            "\t|      default     |   11  |   11  |   11  |   0   ||   11  |   11  |\n",
            "\t---------------------------------------------------------------------\n",
            ":: retrieving :: org.apache.spark#spark-submit-parent-e6aab70d-b453-41bd-8361-ba03fcce1386\n",
            "\tconfs: [default]\n",
            "\t11 artifacts copied, 0 already retrieved (56767kB/54ms)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25/03/18 21:54:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting default log level to \"WARN\".\n",
            "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
          ]
        }
      ],
      "source": [
        "# We will only use 2 cores below to speed up creation of the spark session\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"LearnSparkStreaming\").master(\"local[2]\").getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "VYTXdMSv6cpC",
        "outputId": "e0817f69-3087-4e2c-e643-5ba3ed477a11"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://germayne-ng:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.3.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>LearnSparkStreaming</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x106ebd510>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "spark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36cRSgfTNXXA"
      },
      "source": [
        "## Read and Analyze Kafka stream in \"Batch\" Mode\n",
        "\n",
        "Let's start with reading and analyzing our `pizza-orders` kafka topic in the usual \"batch\" mode of Spark SQL and Dataframes. This is akin to the batch queries we did in the previous lesson. In this case we are taking the messages with the earliest to latest offsets of the topic as a single \"batch\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "6fZDMWC26dJ0"
      },
      "outputs": [],
      "source": [
        "pizza_df = spark.read.format('kafka')\\\n",
        "    .options(**options)\\\n",
        "    .load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJLqrFeXOXpG",
        "outputId": "56b04137-b3cc-4231-e23a-ea7f16977956"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- key: binary (nullable = true)\n",
            " |-- value: binary (nullable = true)\n",
            " |-- topic: string (nullable = true)\n",
            " |-- partition: integer (nullable = true)\n",
            " |-- offset: long (nullable = true)\n",
            " |-- timestamp: timestamp (nullable = true)\n",
            " |-- timestampType: integer (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "pizza_df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+------------+---------+------+--------------------+-------------+\n",
            "|                 key|               value|       topic|partition|offset|           timestamp|timestampType|\n",
            "+--------------------+--------------------+------------+---------+------+--------------------+-------------+\n",
            "|[7B 22 73 68 6F 7...|[7B 22 69 64 22 3...|pizza-orders|        0|     0|2025-03-18 21:52:...|            0|\n",
            "|[7B 22 73 68 6F 7...|[7B 22 69 64 22 3...|pizza-orders|        0|     1|2025-03-18 21:52:...|            0|\n",
            "|[7B 22 73 68 6F 7...|[7B 22 69 64 22 3...|pizza-orders|        0|     2|2025-03-18 21:52:...|            0|\n",
            "|[7B 22 73 68 6F 7...|[7B 22 69 64 22 3...|pizza-orders|        0|     3|2025-03-18 21:53:...|            0|\n",
            "|[7B 22 73 68 6F 7...|[7B 22 69 64 22 3...|pizza-orders|        0|     4|2025-03-18 21:53:...|            0|\n",
            "|[7B 22 73 68 6F 7...|[7B 22 69 64 22 3...|pizza-orders|        0|     5|2025-03-18 21:53:...|            0|\n",
            "|[7B 22 73 68 6F 7...|[7B 22 69 64 22 3...|pizza-orders|        0|     6|2025-03-18 21:53:...|            0|\n",
            "|[7B 22 73 68 6F 7...|[7B 22 69 64 22 3...|pizza-orders|        0|     7|2025-03-18 21:53:...|            0|\n",
            "|[7B 22 73 68 6F 7...|[7B 22 69 64 22 3...|pizza-orders|        0|     8|2025-03-18 21:53:...|            0|\n",
            "+--------------------+--------------------+------------+---------+------+--------------------+-------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "pizza_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5--uyDySFSEB",
        "outputId": "30d90a0a-8d05-4ae7-8ad6-dcdba0677464"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+\n",
            "|                 key|               value|\n",
            "+--------------------+--------------------+\n",
            "|{\"shop\": \"Circula...|{\"id\": 1, \"shop\":...|\n",
            "|{\"shop\": \"Luigis ...|{\"id\": 2, \"shop\":...|\n",
            "|{\"shop\": \"Luigis ...|{\"id\": 3, \"shop\":...|\n",
            "|{\"shop\": \"Circula...|{\"id\": 4, \"shop\":...|\n",
            "|{\"shop\": \"Its-a m...|{\"id\": 5, \"shop\":...|\n",
            "|{\"shop\": \"Circula...|{\"id\": 6, \"shop\":...|\n",
            "|{\"shop\": \"Marios ...|{\"id\": 7, \"shop\":...|\n",
            "|{\"shop\": \"Ill Mak...|{\"id\": 8, \"shop\":...|\n",
            "|{\"shop\": \"Mammami...|{\"id\": 9, \"shop\":...|\n",
            "+--------------------+--------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "pizza_df.selectExpr(\"CAST(key AS STRING)\", \"CAST(value AS STRING)\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "m_zjPQ6_FUVE"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import from_json, col\n",
        "from pyspark.sql.types import StringType, IntegerType, LongType, DoubleType, StructType, ArrayType, StructField"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "owyJGHliQdBG"
      },
      "outputs": [],
      "source": [
        "pizza_schema = StructType([\n",
        "  StructField(\"pizzaName\", StringType()),\n",
        "  StructField(\"additionalToppings\", ArrayType(StringType())),\n",
        "])\n",
        "\n",
        "order_schema = StructType([\n",
        "  StructField(\"address\", StringType()),\n",
        "  StructField(\"id\", IntegerType()),\n",
        "  StructField(\"name\", StringType()),\n",
        "  StructField(\"phoneNumber\", StringType()),\n",
        "  StructField(\"shop\", StringType()),\n",
        "  StructField(\"cost\", DoubleType()),\n",
        "  StructField(\"pizzas\", ArrayType(pizza_schema)),\n",
        "  StructField(\"timestamp\", LongType()),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "8_KAqsS7Q4_5"
      },
      "outputs": [],
      "source": [
        "parsed_df = pizza_df.select(\"timestamp\", from_json(col(\"value\").cast(\"string\"), order_schema).alias(\"value\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7MWOtWPRM-0",
        "outputId": "af678ae7-e0be-4117-88b9-27cdd9fd8e3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- timestamp: timestamp (nullable = true)\n",
            " |-- value: struct (nullable = true)\n",
            " |    |-- address: string (nullable = true)\n",
            " |    |-- id: integer (nullable = true)\n",
            " |    |-- name: string (nullable = true)\n",
            " |    |-- phoneNumber: string (nullable = true)\n",
            " |    |-- shop: string (nullable = true)\n",
            " |    |-- cost: double (nullable = true)\n",
            " |    |-- pizzas: array (nullable = true)\n",
            " |    |    |-- element: struct (containsNull = true)\n",
            " |    |    |    |-- pizzaName: string (nullable = true)\n",
            " |    |    |    |-- additionalToppings: array (nullable = true)\n",
            " |    |    |    |    |-- element: string (containsNull = true)\n",
            " |    |-- timestamp: long (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "parsed_df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mio4VUyERh1H",
        "outputId": "36c7f7d8-3f03-41dd-9425-5859d45bd940"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|timestamp              |value                                                                                                                                                                                                                                                                                                                        |\n",
            "+-----------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|2025-03-18 21:52:55.545|{21087 Calvin Plains\\nJonesland, NY 76392, 1, Jessica Smith, 001-701-915-3000, Circular Pi Pizzeria, 3.3, [{Marinara, []}], 1742305975545}                                                                                                                                                                                   |\n",
            "|2025-03-18 21:52:57.549|{19721 Drew Key\\nNew Donaldport, NH 05690, 2, Roger Brown, 475-943-3780x8105, Luigis Pizza, 45.29, [{Margherita, [🐟 tuna, 🍌 banana]}, {Diavola, []}, {Salami, [🍅 tomato, 🍌 banana]}, {Diavola, [🧅 onion, 🍌 banana]}], 1742305977548}                                                                                   |\n",
            "|2025-03-18 21:52:59.553|{278 Phillips Crossing Apt. 661\\nPort Maryfurt, GU 86535, 3, Matthew Williams, 924-927-0965x759, Luigis Pizza, 24.15, [{Salami, [🧅 onion]}, {Diavola, []}], 1742305979553}                                                                                                                                                  |\n",
            "|2025-03-18 21:53:00.559|{547 Brenda Walks\\nLake Ronaldborough, CT 52490, 4, Corey Rodriguez, 001-629-242-5711x630, Circular Pi Pizzeria, 12.82, [{Salami, [🫑 green peppers]}, {Diavola, [🧅 onion]}, {Salami, [🌶️ hot pepper]}, {Diavola, [🍌 banana, 🧀 blue cheese]}, {Margherita, [🥚 egg, 🥚 egg]}], 1742305980559}                            |\n",
            "|2025-03-18 21:53:02.57 |{752 Brandon Expressway Apt. 815\\nNorth Elizabeth, AR 84161, 5, Stephen Stevens, 253.786.2934, Its-a me! Mario Pizza!, 4.53, [{Salami, [🌶️ hot pepper, 🍌 banana]}, {Margherita, [🐟 tuna, 🍍 pineapple]}, {Marinara, [🐟 tuna, 🫑 green peppers, 🍓 strawberry]}], 1742305982568}                                          |\n",
            "|2025-03-18 21:53:04.58 |{144 Ross Port\\nAliciafurt, KY 28535, 6, Ricky Sexton, 8667536484, Circular Pi Pizzeria, 24.47, [{Margherita, [🥓 bacon, 🍅 tomato]}, {Marinara, [🐟 tuna]}, {Mari & Monti, [🧄 garlic]}, {Salami, []}], 1742305984579}                                                                                                      |\n",
            "|2025-03-18 21:53:05.586|{49595 Gary Port Suite 707\\nNorth Michaelfort, CA 18853, 7, Russell Sanders, (873)972-6401x764, Marios Pizza, 27.58, [{Diavola, [🫒 olives, 🌶️ hot pepper]}, {Salami, [🍅 tomato]}], 1742305985585}                                                                                                                         |\n",
            "|2025-03-18 21:53:07.594|{4189 Madison Glens Suite 206\\nLake Vickiborough, TN 20792, 8, Stephanie Rivera, (544)795-9493x841, Ill Make You a Pizza You Cant Refuse, 39.86, [{Diavola, []}, {Diavola, [🫑 green peppers, 🌶️ hot pepper]}, {Diavola, [🍍 pineapple, 🍍 pineapple]}, {Diavola, [🍌 banana, 🧄 garlic, 🫑 green peppers]}], 1742305987593}|\n",
            "|2025-03-18 21:53:09.599|{77289 Dustin Villages\\nLake Frank, NY 99386, 9, Kelli Hamilton DDS, 244-779-3581, Mammamia Pizza, 38.72, [{Mari & Monti, []}], 1742305989598}                                                                                                                                                                               |\n",
            "+-----------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "parsed_df.show(truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdYUKmrygE7_"
      },
      "source": [
        "We can use _dot notation_ to select the field within a `Struct`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qt_TUX3_edrK",
        "outputId": "8907d09f-371c-4c04-8912-a91348b40c3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+\n",
            "| cost|\n",
            "+-----+\n",
            "|  3.3|\n",
            "|45.29|\n",
            "|24.15|\n",
            "|12.82|\n",
            "| 4.53|\n",
            "|24.47|\n",
            "|27.58|\n",
            "|39.86|\n",
            "|38.72|\n",
            "+-----+\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "parsed_df.select(\"value.cost\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgfNZXpVgXz_"
      },
      "source": [
        "Computing the \"total revenue\" per shop:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqZHVVFggUYv",
        "outputId": "5c140144-c405-44d5-ff32-e38bdd0cab0b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 3:>                                                          (0 + 1) / 1]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------------------------------------+-----------------------+\n",
            "|shop                                |sum(value.cost AS cost)|\n",
            "+------------------------------------+-----------------------+\n",
            "|Ill Make You a Pizza You Cant Refuse|39.86                  |\n",
            "|Luigis Pizza                        |69.44                  |\n",
            "|Mammamia Pizza                      |38.72                  |\n",
            "|Its-a me! Mario Pizza!              |4.53                   |\n",
            "|Marios Pizza                        |27.58                  |\n",
            "|Circular Pi Pizzeria                |40.59                  |\n",
            "+------------------------------------+-----------------------+\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "parsed_df.groupBy(\"value.shop\").sum(\"value.cost\").show(truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GuvYqRChU_v"
      },
      "source": [
        "> 1. Count the no. of orders by shop.\n",
        "> 2. Compute the avg revenue by shop and sort by highest to lowest."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "fEuCpW_Pgk1Q"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import min, max"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8IhcetFiY24",
        "outputId": "7af16123-be01-4746-e028-2d0f66212964"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------------------+-----------------------+\n",
            "|min(timestamp)         |max(timestamp)         |\n",
            "+-----------------------+-----------------------+\n",
            "|2025-03-18 21:52:55.545|2025-03-18 21:53:09.599|\n",
            "+-----------------------+-----------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "parsed_df.select(min(\"timestamp\"), max(\"timestamp\")).show(truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MDIcbPs74B3"
      },
      "source": [
        "## Read and Analyze Kafka stream in \"Streaming\" Mode\n",
        "\n",
        "The key idea in Structured Streaming is to treat a live data stream as a table that is being continuously appended. This leads to a new stream processing model that is very similar to a batch processing model. You will express your streaming computation as standard batch-like query as on a static table, and Spark runs it as an incremental query on the *unbounded input table*. Let’s understand this model in more detail.\n",
        "\n",
        "Consider the input data stream as the “Input Table”. Every data item that is arriving on the stream is like a new row being appended to the Input Table.\n",
        "\n",
        "![concept](https://spark.apache.org/docs/latest/img/structured-streaming-stream-as-a-table.png)\n",
        "\n",
        "A query on the input will generate the “Result Table”. Every trigger interval (say, every 1 second), new rows get appended to the Input Table, which eventually updates the Result Table. Whenever the result table gets updated, we would want to write the changed result rows to an external sink.\n",
        "\n",
        "![result table](https://spark.apache.org/docs/latest/img/structured-streaming-model.png)\n",
        "\n",
        "To illustrate the use of this model, let’s understand the model in context of a word count model. The first lines DataFrame is the input table, and the final wordCounts DataFrame is the result table. Note that the query on streaming lines DataFrame to generate wordCounts is exactly the same as it would be a static DataFrame. However, when this query is started, Spark will continuously check for new data from the socket connection. If there is new data, Spark will run an “incremental” query that combines the previous running counts with the new data to compute updated counts, as shown below.\n",
        "\n",
        "![example](https://spark.apache.org/docs/latest/img/structured-streaming-example-model.png)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9A-q7BY9F_F"
      },
      "source": [
        "Event-time is the time embedded in the data itself. For many applications, you may want to operate on this event-time.\n",
        "\n",
        "For example, if you want to get the number of events generated by IoT devices every minute, then you probably want to use the time when the data was generated (that is, event-time in the data), rather than the time Spark receives them.\n",
        "\n",
        "This event-time is very naturally expressed in this model – each event from the devices is a row in the table, and event-time is a column value in the row. This allows window-based aggregations (e.g. number of events every minute) to be just a special type of grouping and aggregation on the event-time column – each time window is a group and each row can belong to multiple windows/groups. Therefore, such event-time-window-based aggregation queries can be defined consistently on both a static dataset (e.g. from collected device events logs) as well as on a data stream, making the life of the user much easier.\n",
        "\n",
        "Furthermore, this model naturally handles data that has arrived later than expected based on its event-time. Since Spark is updating the Result Table, it has full control over updating old aggregates when there is late data, as well as cleaning up old aggregates to limit the size of intermediate state data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "TKfF1Mc9STFX"
      },
      "outputs": [],
      "source": [
        "pizza_df = spark.readStream.format('kafka')\\\n",
        "    .options(**options)\\\n",
        "    .load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ss8wgrNDkwuW",
        "outputId": "d0f3d31d-d229-46f7-db9b-9a893ca8f44b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pizza_df.isStreaming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grlYCt8Ujg3G",
        "outputId": "3048feba-75ec-40bd-9f1f-6b9bd8788622"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- key: binary (nullable = true)\n",
            " |-- value: binary (nullable = true)\n",
            " |-- topic: string (nullable = true)\n",
            " |-- partition: integer (nullable = true)\n",
            " |-- offset: long (nullable = true)\n",
            " |-- timestamp: timestamp (nullable = true)\n",
            " |-- timestampType: integer (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "pizza_df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "G_vL4jkTjl2v"
      },
      "outputs": [],
      "source": [
        "parsed_df = pizza_df.select(\"timestamp\", from_json(col(\"value\").cast(\"string\"), order_schema).alias(\"value\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1ETDCxskFZ9",
        "outputId": "9b7b3a27-13c7-447a-d5cd-2a02d0d55892"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- timestamp: timestamp (nullable = true)\n",
            " |-- value: struct (nullable = true)\n",
            " |    |-- address: string (nullable = true)\n",
            " |    |-- id: integer (nullable = true)\n",
            " |    |-- name: string (nullable = true)\n",
            " |    |-- phoneNumber: string (nullable = true)\n",
            " |    |-- shop: string (nullable = true)\n",
            " |    |-- cost: double (nullable = true)\n",
            " |    |-- pizzas: array (nullable = true)\n",
            " |    |    |-- element: struct (containsNull = true)\n",
            " |    |    |    |-- pizzaName: string (nullable = true)\n",
            " |    |    |    |-- additionalToppings: array (nullable = true)\n",
            " |    |    |    |    |-- element: string (containsNull = true)\n",
            " |    |-- timestamp: long (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "parsed_df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "zY8eDSs9kLan",
        "outputId": "c4ae7110-9517-4f0d-bf8a-d767fb4c8c55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25/03/18 22:08:40 WARN ResolveWriteToStream: Temporary checkpoint location created which is deleted normally when the query didn't fail: /private/var/folders/z9/_l65135549l_v6k4d3tz369r0000gn/T/temporary-5fa09916-1c31-4cf2-bb84-be9dae426409. If it's required to delete it under any circumstances, please set spark.sql.streaming.forceDeleteTempCheckpointLocation to true. Important to know deleting temp checkpoint folder is best effort.\n",
            "25/03/18 22:08:40 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------\n",
            "Batch: 0\n",
            "-------------------------------------------\n",
            "+---------+-----+\n",
            "|timestamp|value|\n",
            "+---------+-----+\n",
            "+---------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "query = parsed_df \\\n",
        "    .writeStream \\\n",
        "    .format(\"console\") \\\n",
        "    .start()\n",
        "\n",
        "query.awaitTermination() # stops the script from exiting\n",
        "# query.isActive\n",
        "# query.recentProgress\n",
        "# query.stop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "query.stop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'id': '590d73ca-0eaa-4c3b-a9d7-47794ea5a5cd',\n",
              "  'runId': '88fc1108-a1e5-43f6-8593-a3f277ef2afe',\n",
              "  'name': None,\n",
              "  'timestamp': '2025-03-18T14:08:40.658Z',\n",
              "  'batchId': 0,\n",
              "  'numInputRows': 0,\n",
              "  'inputRowsPerSecond': 0.0,\n",
              "  'processedRowsPerSecond': 0.0,\n",
              "  'durationMs': {'addBatch': 23,\n",
              "   'getBatch': 1,\n",
              "   'latestOffset': 3254,\n",
              "   'queryPlanning': 7,\n",
              "   'triggerExecution': 3482,\n",
              "   'walCommit': 90},\n",
              "  'stateOperators': [],\n",
              "  'sources': [{'description': 'KafkaV2[Subscribe[pizza-orders]]',\n",
              "    'startOffset': None,\n",
              "    'endOffset': {'pizza-orders': {'0': 9}},\n",
              "    'latestOffset': {'pizza-orders': {'0': 9}},\n",
              "    'numInputRows': 0,\n",
              "    'inputRowsPerSecond': 0.0,\n",
              "    'processedRowsPerSecond': 0.0,\n",
              "    'metrics': {'avgOffsetsBehindLatest': '0.0',\n",
              "     'maxOffsetsBehindLatest': '0',\n",
              "     'minOffsetsBehindLatest': '0'}}],\n",
              "  'sink': {'description': 'org.apache.spark.sql.execution.streaming.ConsoleTable$@6f418af6',\n",
              "   'numOutputRows': 0}},\n",
              " {'id': '590d73ca-0eaa-4c3b-a9d7-47794ea5a5cd',\n",
              "  'runId': '88fc1108-a1e5-43f6-8593-a3f277ef2afe',\n",
              "  'name': None,\n",
              "  'timestamp': '2025-03-18T14:08:54.147Z',\n",
              "  'batchId': 1,\n",
              "  'numInputRows': 0,\n",
              "  'inputRowsPerSecond': 0.0,\n",
              "  'processedRowsPerSecond': 0.0,\n",
              "  'durationMs': {'latestOffset': 4, 'triggerExecution': 4},\n",
              "  'stateOperators': [],\n",
              "  'sources': [{'description': 'KafkaV2[Subscribe[pizza-orders]]',\n",
              "    'startOffset': {'pizza-orders': {'0': 9}},\n",
              "    'endOffset': {'pizza-orders': {'0': 9}},\n",
              "    'latestOffset': {'pizza-orders': {'0': 9}},\n",
              "    'numInputRows': 0,\n",
              "    'inputRowsPerSecond': 0.0,\n",
              "    'processedRowsPerSecond': 0.0,\n",
              "    'metrics': {'avgOffsetsBehindLatest': '0.0',\n",
              "     'maxOffsetsBehindLatest': '0',\n",
              "     'minOffsetsBehindLatest': '0'}}],\n",
              "  'sink': {'description': 'org.apache.spark.sql.execution.streaming.ConsoleTable$@6f418af6',\n",
              "   'numOutputRows': 0}},\n",
              " {'id': '590d73ca-0eaa-4c3b-a9d7-47794ea5a5cd',\n",
              "  'runId': '88fc1108-a1e5-43f6-8593-a3f277ef2afe',\n",
              "  'name': None,\n",
              "  'timestamp': '2025-03-18T14:09:04.156Z',\n",
              "  'batchId': 1,\n",
              "  'numInputRows': 0,\n",
              "  'inputRowsPerSecond': 0.0,\n",
              "  'processedRowsPerSecond': 0.0,\n",
              "  'durationMs': {'latestOffset': 2, 'triggerExecution': 2},\n",
              "  'stateOperators': [],\n",
              "  'sources': [{'description': 'KafkaV2[Subscribe[pizza-orders]]',\n",
              "    'startOffset': {'pizza-orders': {'0': 9}},\n",
              "    'endOffset': {'pizza-orders': {'0': 9}},\n",
              "    'latestOffset': {'pizza-orders': {'0': 9}},\n",
              "    'numInputRows': 0,\n",
              "    'inputRowsPerSecond': 0.0,\n",
              "    'processedRowsPerSecond': 0.0,\n",
              "    'metrics': {'avgOffsetsBehindLatest': '0.0',\n",
              "     'maxOffsetsBehindLatest': '0',\n",
              "     'minOffsetsBehindLatest': '0'}}],\n",
              "  'sink': {'description': 'org.apache.spark.sql.execution.streaming.ConsoleTable$@6f418af6',\n",
              "   'numOutputRows': 0}},\n",
              " {'id': '590d73ca-0eaa-4c3b-a9d7-47794ea5a5cd',\n",
              "  'runId': '88fc1108-a1e5-43f6-8593-a3f277ef2afe',\n",
              "  'name': None,\n",
              "  'timestamp': '2025-03-18T14:09:14.169Z',\n",
              "  'batchId': 1,\n",
              "  'numInputRows': 0,\n",
              "  'inputRowsPerSecond': 0.0,\n",
              "  'processedRowsPerSecond': 0.0,\n",
              "  'durationMs': {'latestOffset': 2, 'triggerExecution': 2},\n",
              "  'stateOperators': [],\n",
              "  'sources': [{'description': 'KafkaV2[Subscribe[pizza-orders]]',\n",
              "    'startOffset': {'pizza-orders': {'0': 9}},\n",
              "    'endOffset': {'pizza-orders': {'0': 9}},\n",
              "    'latestOffset': {'pizza-orders': {'0': 9}},\n",
              "    'numInputRows': 0,\n",
              "    'inputRowsPerSecond': 0.0,\n",
              "    'processedRowsPerSecond': 0.0,\n",
              "    'metrics': {'avgOffsetsBehindLatest': '0.0',\n",
              "     'maxOffsetsBehindLatest': '0',\n",
              "     'minOffsetsBehindLatest': '0'}}],\n",
              "  'sink': {'description': 'org.apache.spark.sql.execution.streaming.ConsoleTable$@6f418af6',\n",
              "   'numOutputRows': 0}},\n",
              " {'id': '590d73ca-0eaa-4c3b-a9d7-47794ea5a5cd',\n",
              "  'runId': '88fc1108-a1e5-43f6-8593-a3f277ef2afe',\n",
              "  'name': None,\n",
              "  'timestamp': '2025-03-18T14:09:24.179Z',\n",
              "  'batchId': 1,\n",
              "  'numInputRows': 0,\n",
              "  'inputRowsPerSecond': 0.0,\n",
              "  'processedRowsPerSecond': 0.0,\n",
              "  'durationMs': {'latestOffset': 3, 'triggerExecution': 4},\n",
              "  'stateOperators': [],\n",
              "  'sources': [{'description': 'KafkaV2[Subscribe[pizza-orders]]',\n",
              "    'startOffset': {'pizza-orders': {'0': 9}},\n",
              "    'endOffset': {'pizza-orders': {'0': 9}},\n",
              "    'latestOffset': {'pizza-orders': {'0': 9}},\n",
              "    'numInputRows': 0,\n",
              "    'inputRowsPerSecond': 0.0,\n",
              "    'processedRowsPerSecond': 0.0,\n",
              "    'metrics': {'avgOffsetsBehindLatest': '0.0',\n",
              "     'maxOffsetsBehindLatest': '0',\n",
              "     'minOffsetsBehindLatest': '0'}}],\n",
              "  'sink': {'description': 'org.apache.spark.sql.execution.streaming.ConsoleTable$@6f418af6',\n",
              "   'numOutputRows': 0}},\n",
              " {'id': '590d73ca-0eaa-4c3b-a9d7-47794ea5a5cd',\n",
              "  'runId': '88fc1108-a1e5-43f6-8593-a3f277ef2afe',\n",
              "  'name': None,\n",
              "  'timestamp': '2025-03-18T14:09:34.193Z',\n",
              "  'batchId': 1,\n",
              "  'numInputRows': 0,\n",
              "  'inputRowsPerSecond': 0.0,\n",
              "  'processedRowsPerSecond': 0.0,\n",
              "  'durationMs': {'latestOffset': 2, 'triggerExecution': 2},\n",
              "  'stateOperators': [],\n",
              "  'sources': [{'description': 'KafkaV2[Subscribe[pizza-orders]]',\n",
              "    'startOffset': {'pizza-orders': {'0': 9}},\n",
              "    'endOffset': {'pizza-orders': {'0': 9}},\n",
              "    'latestOffset': {'pizza-orders': {'0': 9}},\n",
              "    'numInputRows': 0,\n",
              "    'inputRowsPerSecond': 0.0,\n",
              "    'processedRowsPerSecond': 0.0,\n",
              "    'metrics': {'avgOffsetsBehindLatest': '0.0',\n",
              "     'maxOffsetsBehindLatest': '0',\n",
              "     'minOffsetsBehindLatest': '0'}}],\n",
              "  'sink': {'description': 'org.apache.spark.sql.execution.streaming.ConsoleTable$@6f418af6',\n",
              "   'numOutputRows': 0}},\n",
              " {'id': '590d73ca-0eaa-4c3b-a9d7-47794ea5a5cd',\n",
              "  'runId': '88fc1108-a1e5-43f6-8593-a3f277ef2afe',\n",
              "  'name': None,\n",
              "  'timestamp': '2025-03-18T14:09:44.203Z',\n",
              "  'batchId': 1,\n",
              "  'numInputRows': 0,\n",
              "  'inputRowsPerSecond': 0.0,\n",
              "  'processedRowsPerSecond': 0.0,\n",
              "  'durationMs': {'latestOffset': 2, 'triggerExecution': 2},\n",
              "  'stateOperators': [],\n",
              "  'sources': [{'description': 'KafkaV2[Subscribe[pizza-orders]]',\n",
              "    'startOffset': {'pizza-orders': {'0': 9}},\n",
              "    'endOffset': {'pizza-orders': {'0': 9}},\n",
              "    'latestOffset': {'pizza-orders': {'0': 9}},\n",
              "    'numInputRows': 0,\n",
              "    'inputRowsPerSecond': 0.0,\n",
              "    'processedRowsPerSecond': 0.0,\n",
              "    'metrics': {'avgOffsetsBehindLatest': '0.0',\n",
              "     'maxOffsetsBehindLatest': '0',\n",
              "     'minOffsetsBehindLatest': '0'}}],\n",
              "  'sink': {'description': 'org.apache.spark.sql.execution.streaming.ConsoleTable$@6f418af6',\n",
              "   'numOutputRows': 0}},\n",
              " {'id': '590d73ca-0eaa-4c3b-a9d7-47794ea5a5cd',\n",
              "  'runId': '88fc1108-a1e5-43f6-8593-a3f277ef2afe',\n",
              "  'name': None,\n",
              "  'timestamp': '2025-03-18T14:09:54.217Z',\n",
              "  'batchId': 1,\n",
              "  'numInputRows': 0,\n",
              "  'inputRowsPerSecond': 0.0,\n",
              "  'processedRowsPerSecond': 0.0,\n",
              "  'durationMs': {'latestOffset': 5, 'triggerExecution': 5},\n",
              "  'stateOperators': [],\n",
              "  'sources': [{'description': 'KafkaV2[Subscribe[pizza-orders]]',\n",
              "    'startOffset': {'pizza-orders': {'0': 9}},\n",
              "    'endOffset': {'pizza-orders': {'0': 9}},\n",
              "    'latestOffset': {'pizza-orders': {'0': 9}},\n",
              "    'numInputRows': 0,\n",
              "    'inputRowsPerSecond': 0.0,\n",
              "    'processedRowsPerSecond': 0.0,\n",
              "    'metrics': {'avgOffsetsBehindLatest': '0.0',\n",
              "     'maxOffsetsBehindLatest': '0',\n",
              "     'minOffsetsBehindLatest': '0'}}],\n",
              "  'sink': {'description': 'org.apache.spark.sql.execution.streaming.ConsoleTable$@6f418af6',\n",
              "   'numOutputRows': 0}},\n",
              " {'id': '590d73ca-0eaa-4c3b-a9d7-47794ea5a5cd',\n",
              "  'runId': '88fc1108-a1e5-43f6-8593-a3f277ef2afe',\n",
              "  'name': None,\n",
              "  'timestamp': '2025-03-18T14:10:04.234Z',\n",
              "  'batchId': 1,\n",
              "  'numInputRows': 0,\n",
              "  'inputRowsPerSecond': 0.0,\n",
              "  'processedRowsPerSecond': 0.0,\n",
              "  'durationMs': {'latestOffset': 12, 'triggerExecution': 12},\n",
              "  'stateOperators': [],\n",
              "  'sources': [{'description': 'KafkaV2[Subscribe[pizza-orders]]',\n",
              "    'startOffset': {'pizza-orders': {'0': 9}},\n",
              "    'endOffset': {'pizza-orders': {'0': 9}},\n",
              "    'latestOffset': {'pizza-orders': {'0': 9}},\n",
              "    'numInputRows': 0,\n",
              "    'inputRowsPerSecond': 0.0,\n",
              "    'processedRowsPerSecond': 0.0,\n",
              "    'metrics': {'avgOffsetsBehindLatest': '0.0',\n",
              "     'maxOffsetsBehindLatest': '0',\n",
              "     'minOffsetsBehindLatest': '0'}}],\n",
              "  'sink': {'description': 'org.apache.spark.sql.execution.streaming.ConsoleTable$@6f418af6',\n",
              "   'numOutputRows': 0}},\n",
              " {'id': '590d73ca-0eaa-4c3b-a9d7-47794ea5a5cd',\n",
              "  'runId': '88fc1108-a1e5-43f6-8593-a3f277ef2afe',\n",
              "  'name': None,\n",
              "  'timestamp': '2025-03-18T14:10:14.221Z',\n",
              "  'batchId': 1,\n",
              "  'numInputRows': 0,\n",
              "  'inputRowsPerSecond': 0.0,\n",
              "  'processedRowsPerSecond': 0.0,\n",
              "  'durationMs': {'latestOffset': 55, 'triggerExecution': 55},\n",
              "  'stateOperators': [],\n",
              "  'sources': [{'description': 'KafkaV2[Subscribe[pizza-orders]]',\n",
              "    'startOffset': {'pizza-orders': {'0': 9}},\n",
              "    'endOffset': {'pizza-orders': {'0': 9}},\n",
              "    'latestOffset': {'pizza-orders': {'0': 9}},\n",
              "    'numInputRows': 0,\n",
              "    'inputRowsPerSecond': 0.0,\n",
              "    'processedRowsPerSecond': 0.0,\n",
              "    'metrics': {'avgOffsetsBehindLatest': '0.0',\n",
              "     'maxOffsetsBehindLatest': '0',\n",
              "     'minOffsetsBehindLatest': '0'}}],\n",
              "  'sink': {'description': 'org.apache.spark.sql.execution.streaming.ConsoleTable$@6f418af6',\n",
              "   'numOutputRows': 0}},\n",
              " {'id': '590d73ca-0eaa-4c3b-a9d7-47794ea5a5cd',\n",
              "  'runId': '88fc1108-a1e5-43f6-8593-a3f277ef2afe',\n",
              "  'name': None,\n",
              "  'timestamp': '2025-03-18T14:10:24.280Z',\n",
              "  'batchId': 1,\n",
              "  'numInputRows': 0,\n",
              "  'inputRowsPerSecond': 0.0,\n",
              "  'processedRowsPerSecond': 0.0,\n",
              "  'durationMs': {'latestOffset': 5, 'triggerExecution': 5},\n",
              "  'stateOperators': [],\n",
              "  'sources': [{'description': 'KafkaV2[Subscribe[pizza-orders]]',\n",
              "    'startOffset': {'pizza-orders': {'0': 9}},\n",
              "    'endOffset': {'pizza-orders': {'0': 9}},\n",
              "    'latestOffset': {'pizza-orders': {'0': 9}},\n",
              "    'numInputRows': 0,\n",
              "    'inputRowsPerSecond': 0.0,\n",
              "    'processedRowsPerSecond': 0.0,\n",
              "    'metrics': {'avgOffsetsBehindLatest': '0.0',\n",
              "     'maxOffsetsBehindLatest': '0',\n",
              "     'minOffsetsBehindLatest': '0'}}],\n",
              "  'sink': {'description': 'org.apache.spark.sql.execution.streaming.ConsoleTable$@6f418af6',\n",
              "   'numOutputRows': 0}},\n",
              " {'id': '590d73ca-0eaa-4c3b-a9d7-47794ea5a5cd',\n",
              "  'runId': '88fc1108-a1e5-43f6-8593-a3f277ef2afe',\n",
              "  'name': None,\n",
              "  'timestamp': '2025-03-18T14:10:34.291Z',\n",
              "  'batchId': 1,\n",
              "  'numInputRows': 0,\n",
              "  'inputRowsPerSecond': 0.0,\n",
              "  'processedRowsPerSecond': 0.0,\n",
              "  'durationMs': {'latestOffset': 12, 'triggerExecution': 12},\n",
              "  'stateOperators': [],\n",
              "  'sources': [{'description': 'KafkaV2[Subscribe[pizza-orders]]',\n",
              "    'startOffset': {'pizza-orders': {'0': 9}},\n",
              "    'endOffset': {'pizza-orders': {'0': 9}},\n",
              "    'latestOffset': {'pizza-orders': {'0': 9}},\n",
              "    'numInputRows': 0,\n",
              "    'inputRowsPerSecond': 0.0,\n",
              "    'processedRowsPerSecond': 0.0,\n",
              "    'metrics': {'avgOffsetsBehindLatest': '0.0',\n",
              "     'maxOffsetsBehindLatest': '0',\n",
              "     'minOffsetsBehindLatest': '0'}}],\n",
              "  'sink': {'description': 'org.apache.spark.sql.execution.streaming.ConsoleTable$@6f418af6',\n",
              "   'numOutputRows': 0}},\n",
              " {'id': '590d73ca-0eaa-4c3b-a9d7-47794ea5a5cd',\n",
              "  'runId': '88fc1108-a1e5-43f6-8593-a3f277ef2afe',\n",
              "  'name': None,\n",
              "  'timestamp': '2025-03-18T14:10:44.309Z',\n",
              "  'batchId': 1,\n",
              "  'numInputRows': 0,\n",
              "  'inputRowsPerSecond': 0.0,\n",
              "  'processedRowsPerSecond': 0.0,\n",
              "  'durationMs': {'latestOffset': 3, 'triggerExecution': 3},\n",
              "  'stateOperators': [],\n",
              "  'sources': [{'description': 'KafkaV2[Subscribe[pizza-orders]]',\n",
              "    'startOffset': {'pizza-orders': {'0': 9}},\n",
              "    'endOffset': {'pizza-orders': {'0': 9}},\n",
              "    'latestOffset': {'pizza-orders': {'0': 9}},\n",
              "    'numInputRows': 0,\n",
              "    'inputRowsPerSecond': 0.0,\n",
              "    'processedRowsPerSecond': 0.0,\n",
              "    'metrics': {'avgOffsetsBehindLatest': '0.0',\n",
              "     'maxOffsetsBehindLatest': '0',\n",
              "     'minOffsetsBehindLatest': '0'}}],\n",
              "  'sink': {'description': 'org.apache.spark.sql.execution.streaming.ConsoleTable$@6f418af6',\n",
              "   'numOutputRows': 0}},\n",
              " {'id': '590d73ca-0eaa-4c3b-a9d7-47794ea5a5cd',\n",
              "  'runId': '88fc1108-a1e5-43f6-8593-a3f277ef2afe',\n",
              "  'name': None,\n",
              "  'timestamp': '2025-03-18T14:10:54.314Z',\n",
              "  'batchId': 1,\n",
              "  'numInputRows': 0,\n",
              "  'inputRowsPerSecond': 0.0,\n",
              "  'processedRowsPerSecond': 0.0,\n",
              "  'durationMs': {'latestOffset': 2, 'triggerExecution': 2},\n",
              "  'stateOperators': [],\n",
              "  'sources': [{'description': 'KafkaV2[Subscribe[pizza-orders]]',\n",
              "    'startOffset': {'pizza-orders': {'0': 9}},\n",
              "    'endOffset': {'pizza-orders': {'0': 9}},\n",
              "    'latestOffset': {'pizza-orders': {'0': 9}},\n",
              "    'numInputRows': 0,\n",
              "    'inputRowsPerSecond': 0.0,\n",
              "    'processedRowsPerSecond': 0.0,\n",
              "    'metrics': {'avgOffsetsBehindLatest': '0.0',\n",
              "     'maxOffsetsBehindLatest': '0',\n",
              "     'minOffsetsBehindLatest': '0'}}],\n",
              "  'sink': {'description': 'org.apache.spark.sql.execution.streaming.ConsoleTable$@6f418af6',\n",
              "   'numOutputRows': 0}},\n",
              " {'id': '590d73ca-0eaa-4c3b-a9d7-47794ea5a5cd',\n",
              "  'runId': '88fc1108-a1e5-43f6-8593-a3f277ef2afe',\n",
              "  'name': None,\n",
              "  'timestamp': '2025-03-18T14:11:04.326Z',\n",
              "  'batchId': 1,\n",
              "  'numInputRows': 0,\n",
              "  'inputRowsPerSecond': 0.0,\n",
              "  'processedRowsPerSecond': 0.0,\n",
              "  'durationMs': {'latestOffset': 3, 'triggerExecution': 3},\n",
              "  'stateOperators': [],\n",
              "  'sources': [{'description': 'KafkaV2[Subscribe[pizza-orders]]',\n",
              "    'startOffset': {'pizza-orders': {'0': 9}},\n",
              "    'endOffset': {'pizza-orders': {'0': 9}},\n",
              "    'latestOffset': {'pizza-orders': {'0': 9}},\n",
              "    'numInputRows': 0,\n",
              "    'inputRowsPerSecond': 0.0,\n",
              "    'processedRowsPerSecond': 0.0,\n",
              "    'metrics': {'avgOffsetsBehindLatest': '0.0',\n",
              "     'maxOffsetsBehindLatest': '0',\n",
              "     'minOffsetsBehindLatest': '0'}}],\n",
              "  'sink': {'description': 'org.apache.spark.sql.execution.streaming.ConsoleTable$@6f418af6',\n",
              "   'numOutputRows': 0}},\n",
              " {'id': '590d73ca-0eaa-4c3b-a9d7-47794ea5a5cd',\n",
              "  'runId': '88fc1108-a1e5-43f6-8593-a3f277ef2afe',\n",
              "  'name': None,\n",
              "  'timestamp': '2025-03-18T14:11:14.332Z',\n",
              "  'batchId': 1,\n",
              "  'numInputRows': 0,\n",
              "  'inputRowsPerSecond': 0.0,\n",
              "  'processedRowsPerSecond': 0.0,\n",
              "  'durationMs': {'latestOffset': 6, 'triggerExecution': 6},\n",
              "  'stateOperators': [],\n",
              "  'sources': [{'description': 'KafkaV2[Subscribe[pizza-orders]]',\n",
              "    'startOffset': {'pizza-orders': {'0': 9}},\n",
              "    'endOffset': {'pizza-orders': {'0': 9}},\n",
              "    'latestOffset': {'pizza-orders': {'0': 9}},\n",
              "    'numInputRows': 0,\n",
              "    'inputRowsPerSecond': 0.0,\n",
              "    'processedRowsPerSecond': 0.0,\n",
              "    'metrics': {'avgOffsetsBehindLatest': '0.0',\n",
              "     'maxOffsetsBehindLatest': '0',\n",
              "     'minOffsetsBehindLatest': '0'}}],\n",
              "  'sink': {'description': 'org.apache.spark.sql.execution.streaming.ConsoleTable$@6f418af6',\n",
              "   'numOutputRows': 0}},\n",
              " {'id': '590d73ca-0eaa-4c3b-a9d7-47794ea5a5cd',\n",
              "  'runId': '88fc1108-a1e5-43f6-8593-a3f277ef2afe',\n",
              "  'name': None,\n",
              "  'timestamp': '2025-03-18T14:11:24.337Z',\n",
              "  'batchId': 1,\n",
              "  'numInputRows': 0,\n",
              "  'inputRowsPerSecond': 0.0,\n",
              "  'processedRowsPerSecond': 0.0,\n",
              "  'durationMs': {'latestOffset': 10, 'triggerExecution': 10},\n",
              "  'stateOperators': [],\n",
              "  'sources': [{'description': 'KafkaV2[Subscribe[pizza-orders]]',\n",
              "    'startOffset': {'pizza-orders': {'0': 9}},\n",
              "    'endOffset': {'pizza-orders': {'0': 9}},\n",
              "    'latestOffset': {'pizza-orders': {'0': 9}},\n",
              "    'numInputRows': 0,\n",
              "    'inputRowsPerSecond': 0.0,\n",
              "    'processedRowsPerSecond': 0.0,\n",
              "    'metrics': {'avgOffsetsBehindLatest': '0.0',\n",
              "     'maxOffsetsBehindLatest': '0',\n",
              "     'minOffsetsBehindLatest': '0'}}],\n",
              "  'sink': {'description': 'org.apache.spark.sql.execution.streaming.ConsoleTable$@6f418af6',\n",
              "   'numOutputRows': 0}},\n",
              " {'id': '590d73ca-0eaa-4c3b-a9d7-47794ea5a5cd',\n",
              "  'runId': '88fc1108-a1e5-43f6-8593-a3f277ef2afe',\n",
              "  'name': None,\n",
              "  'timestamp': '2025-03-18T14:11:34.351Z',\n",
              "  'batchId': 1,\n",
              "  'numInputRows': 0,\n",
              "  'inputRowsPerSecond': 0.0,\n",
              "  'processedRowsPerSecond': 0.0,\n",
              "  'durationMs': {'latestOffset': 8, 'triggerExecution': 8},\n",
              "  'stateOperators': [],\n",
              "  'sources': [{'description': 'KafkaV2[Subscribe[pizza-orders]]',\n",
              "    'startOffset': {'pizza-orders': {'0': 9}},\n",
              "    'endOffset': {'pizza-orders': {'0': 9}},\n",
              "    'latestOffset': {'pizza-orders': {'0': 9}},\n",
              "    'numInputRows': 0,\n",
              "    'inputRowsPerSecond': 0.0,\n",
              "    'processedRowsPerSecond': 0.0,\n",
              "    'metrics': {'avgOffsetsBehindLatest': '0.0',\n",
              "     'maxOffsetsBehindLatest': '0',\n",
              "     'minOffsetsBehindLatest': '0'}}],\n",
              "  'sink': {'description': 'org.apache.spark.sql.execution.streaming.ConsoleTable$@6f418af6',\n",
              "   'numOutputRows': 0}},\n",
              " {'id': '590d73ca-0eaa-4c3b-a9d7-47794ea5a5cd',\n",
              "  'runId': '88fc1108-a1e5-43f6-8593-a3f277ef2afe',\n",
              "  'name': None,\n",
              "  'timestamp': '2025-03-18T14:11:44.364Z',\n",
              "  'batchId': 1,\n",
              "  'numInputRows': 0,\n",
              "  'inputRowsPerSecond': 0.0,\n",
              "  'processedRowsPerSecond': 0.0,\n",
              "  'durationMs': {'latestOffset': 15, 'triggerExecution': 15},\n",
              "  'stateOperators': [],\n",
              "  'sources': [{'description': 'KafkaV2[Subscribe[pizza-orders]]',\n",
              "    'startOffset': {'pizza-orders': {'0': 9}},\n",
              "    'endOffset': {'pizza-orders': {'0': 9}},\n",
              "    'latestOffset': {'pizza-orders': {'0': 9}},\n",
              "    'numInputRows': 0,\n",
              "    'inputRowsPerSecond': 0.0,\n",
              "    'processedRowsPerSecond': 0.0,\n",
              "    'metrics': {'avgOffsetsBehindLatest': '0.0',\n",
              "     'maxOffsetsBehindLatest': '0',\n",
              "     'minOffsetsBehindLatest': '0'}}],\n",
              "  'sink': {'description': 'org.apache.spark.sql.execution.streaming.ConsoleTable$@6f418af6',\n",
              "   'numOutputRows': 0}},\n",
              " {'id': '590d73ca-0eaa-4c3b-a9d7-47794ea5a5cd',\n",
              "  'runId': '88fc1108-a1e5-43f6-8593-a3f277ef2afe',\n",
              "  'name': None,\n",
              "  'timestamp': '2025-03-18T14:11:54.386Z',\n",
              "  'batchId': 1,\n",
              "  'numInputRows': 0,\n",
              "  'inputRowsPerSecond': 0.0,\n",
              "  'processedRowsPerSecond': 0.0,\n",
              "  'durationMs': {'latestOffset': 6, 'triggerExecution': 6},\n",
              "  'stateOperators': [],\n",
              "  'sources': [{'description': 'KafkaV2[Subscribe[pizza-orders]]',\n",
              "    'startOffset': {'pizza-orders': {'0': 9}},\n",
              "    'endOffset': {'pizza-orders': {'0': 9}},\n",
              "    'latestOffset': {'pizza-orders': {'0': 9}},\n",
              "    'numInputRows': 0,\n",
              "    'inputRowsPerSecond': 0.0,\n",
              "    'processedRowsPerSecond': 0.0,\n",
              "    'metrics': {'avgOffsetsBehindLatest': '0.0',\n",
              "     'maxOffsetsBehindLatest': '0',\n",
              "     'minOffsetsBehindLatest': '0'}}],\n",
              "  'sink': {'description': 'org.apache.spark.sql.execution.streaming.ConsoleTable$@6f418af6',\n",
              "   'numOutputRows': 0}},\n",
              " {'id': '590d73ca-0eaa-4c3b-a9d7-47794ea5a5cd',\n",
              "  'runId': '88fc1108-a1e5-43f6-8593-a3f277ef2afe',\n",
              "  'name': None,\n",
              "  'timestamp': '2025-03-18T14:12:04.401Z',\n",
              "  'batchId': 1,\n",
              "  'numInputRows': 0,\n",
              "  'inputRowsPerSecond': 0.0,\n",
              "  'processedRowsPerSecond': 0.0,\n",
              "  'durationMs': {'latestOffset': 6, 'triggerExecution': 6},\n",
              "  'stateOperators': [],\n",
              "  'sources': [{'description': 'KafkaV2[Subscribe[pizza-orders]]',\n",
              "    'startOffset': {'pizza-orders': {'0': 9}},\n",
              "    'endOffset': {'pizza-orders': {'0': 9}},\n",
              "    'latestOffset': {'pizza-orders': {'0': 9}},\n",
              "    'numInputRows': 0,\n",
              "    'inputRowsPerSecond': 0.0,\n",
              "    'processedRowsPerSecond': 0.0,\n",
              "    'metrics': {'avgOffsetsBehindLatest': '0.0',\n",
              "     'maxOffsetsBehindLatest': '0',\n",
              "     'minOffsetsBehindLatest': '0'}}],\n",
              "  'sink': {'description': 'org.apache.spark.sql.execution.streaming.ConsoleTable$@6f418af6',\n",
              "   'numOutputRows': 0}},\n",
              " {'id': '590d73ca-0eaa-4c3b-a9d7-47794ea5a5cd',\n",
              "  'runId': '88fc1108-a1e5-43f6-8593-a3f277ef2afe',\n",
              "  'name': None,\n",
              "  'timestamp': '2025-03-18T14:12:14.414Z',\n",
              "  'batchId': 1,\n",
              "  'numInputRows': 0,\n",
              "  'inputRowsPerSecond': 0.0,\n",
              "  'processedRowsPerSecond': 0.0,\n",
              "  'durationMs': {'latestOffset': 3, 'triggerExecution': 3},\n",
              "  'stateOperators': [],\n",
              "  'sources': [{'description': 'KafkaV2[Subscribe[pizza-orders]]',\n",
              "    'startOffset': {'pizza-orders': {'0': 9}},\n",
              "    'endOffset': {'pizza-orders': {'0': 9}},\n",
              "    'latestOffset': {'pizza-orders': {'0': 9}},\n",
              "    'numInputRows': 0,\n",
              "    'inputRowsPerSecond': 0.0,\n",
              "    'processedRowsPerSecond': 0.0,\n",
              "    'metrics': {'avgOffsetsBehindLatest': '0.0',\n",
              "     'maxOffsetsBehindLatest': '0',\n",
              "     'minOffsetsBehindLatest': '0'}}],\n",
              "  'sink': {'description': 'org.apache.spark.sql.execution.streaming.ConsoleTable$@6f418af6',\n",
              "   'numOutputRows': 0}},\n",
              " {'id': '590d73ca-0eaa-4c3b-a9d7-47794ea5a5cd',\n",
              "  'runId': '88fc1108-a1e5-43f6-8593-a3f277ef2afe',\n",
              "  'name': None,\n",
              "  'timestamp': '2025-03-18T14:12:24.424Z',\n",
              "  'batchId': 1,\n",
              "  'numInputRows': 0,\n",
              "  'inputRowsPerSecond': 0.0,\n",
              "  'processedRowsPerSecond': 0.0,\n",
              "  'durationMs': {'latestOffset': 4, 'triggerExecution': 4},\n",
              "  'stateOperators': [],\n",
              "  'sources': [{'description': 'KafkaV2[Subscribe[pizza-orders]]',\n",
              "    'startOffset': {'pizza-orders': {'0': 9}},\n",
              "    'endOffset': {'pizza-orders': {'0': 9}},\n",
              "    'latestOffset': {'pizza-orders': {'0': 9}},\n",
              "    'numInputRows': 0,\n",
              "    'inputRowsPerSecond': 0.0,\n",
              "    'processedRowsPerSecond': 0.0,\n",
              "    'metrics': {'avgOffsetsBehindLatest': '0.0',\n",
              "     'maxOffsetsBehindLatest': '0',\n",
              "     'minOffsetsBehindLatest': '0'}}],\n",
              "  'sink': {'description': 'org.apache.spark.sql.execution.streaming.ConsoleTable$@6f418af6',\n",
              "   'numOutputRows': 0}},\n",
              " {'id': '590d73ca-0eaa-4c3b-a9d7-47794ea5a5cd',\n",
              "  'runId': '88fc1108-a1e5-43f6-8593-a3f277ef2afe',\n",
              "  'name': None,\n",
              "  'timestamp': '2025-03-18T14:12:34.438Z',\n",
              "  'batchId': 1,\n",
              "  'numInputRows': 0,\n",
              "  'inputRowsPerSecond': 0.0,\n",
              "  'processedRowsPerSecond': 0.0,\n",
              "  'durationMs': {'latestOffset': 10, 'triggerExecution': 10},\n",
              "  'stateOperators': [],\n",
              "  'sources': [{'description': 'KafkaV2[Subscribe[pizza-orders]]',\n",
              "    'startOffset': {'pizza-orders': {'0': 9}},\n",
              "    'endOffset': {'pizza-orders': {'0': 9}},\n",
              "    'latestOffset': {'pizza-orders': {'0': 9}},\n",
              "    'numInputRows': 0,\n",
              "    'inputRowsPerSecond': 0.0,\n",
              "    'processedRowsPerSecond': 0.0,\n",
              "    'metrics': {'avgOffsetsBehindLatest': '0.0',\n",
              "     'maxOffsetsBehindLatest': '0',\n",
              "     'minOffsetsBehindLatest': '0'}}],\n",
              "  'sink': {'description': 'org.apache.spark.sql.execution.streaming.ConsoleTable$@6f418af6',\n",
              "   'numOutputRows': 0}},\n",
              " {'id': '590d73ca-0eaa-4c3b-a9d7-47794ea5a5cd',\n",
              "  'runId': '88fc1108-a1e5-43f6-8593-a3f277ef2afe',\n",
              "  'name': None,\n",
              "  'timestamp': '2025-03-18T14:12:44.460Z',\n",
              "  'batchId': 1,\n",
              "  'numInputRows': 0,\n",
              "  'inputRowsPerSecond': 0.0,\n",
              "  'processedRowsPerSecond': 0.0,\n",
              "  'durationMs': {'latestOffset': 13, 'triggerExecution': 13},\n",
              "  'stateOperators': [],\n",
              "  'sources': [{'description': 'KafkaV2[Subscribe[pizza-orders]]',\n",
              "    'startOffset': {'pizza-orders': {'0': 9}},\n",
              "    'endOffset': {'pizza-orders': {'0': 9}},\n",
              "    'latestOffset': {'pizza-orders': {'0': 9}},\n",
              "    'numInputRows': 0,\n",
              "    'inputRowsPerSecond': 0.0,\n",
              "    'processedRowsPerSecond': 0.0,\n",
              "    'metrics': {'avgOffsetsBehindLatest': '0.0',\n",
              "     'maxOffsetsBehindLatest': '0',\n",
              "     'minOffsetsBehindLatest': '0'}}],\n",
              "  'sink': {'description': 'org.apache.spark.sql.execution.streaming.ConsoleTable$@6f418af6',\n",
              "   'numOutputRows': 0}},\n",
              " {'id': '590d73ca-0eaa-4c3b-a9d7-47794ea5a5cd',\n",
              "  'runId': '88fc1108-a1e5-43f6-8593-a3f277ef2afe',\n",
              "  'name': None,\n",
              "  'timestamp': '2025-03-18T14:12:54.474Z',\n",
              "  'batchId': 1,\n",
              "  'numInputRows': 0,\n",
              "  'inputRowsPerSecond': 0.0,\n",
              "  'processedRowsPerSecond': 0.0,\n",
              "  'durationMs': {'latestOffset': 7, 'triggerExecution': 7},\n",
              "  'stateOperators': [],\n",
              "  'sources': [{'description': 'KafkaV2[Subscribe[pizza-orders]]',\n",
              "    'startOffset': {'pizza-orders': {'0': 9}},\n",
              "    'endOffset': {'pizza-orders': {'0': 9}},\n",
              "    'latestOffset': {'pizza-orders': {'0': 9}},\n",
              "    'numInputRows': 0,\n",
              "    'inputRowsPerSecond': 0.0,\n",
              "    'processedRowsPerSecond': 0.0,\n",
              "    'metrics': {'avgOffsetsBehindLatest': '0.0',\n",
              "     'maxOffsetsBehindLatest': '0',\n",
              "     'minOffsetsBehindLatest': '0'}}],\n",
              "  'sink': {'description': 'org.apache.spark.sql.execution.streaming.ConsoleTable$@6f418af6',\n",
              "   'numOutputRows': 0}},\n",
              " {'id': '590d73ca-0eaa-4c3b-a9d7-47794ea5a5cd',\n",
              "  'runId': '88fc1108-a1e5-43f6-8593-a3f277ef2afe',\n",
              "  'name': None,\n",
              "  'timestamp': '2025-03-18T14:13:04.477Z',\n",
              "  'batchId': 1,\n",
              "  'numInputRows': 0,\n",
              "  'inputRowsPerSecond': 0.0,\n",
              "  'processedRowsPerSecond': 0.0,\n",
              "  'durationMs': {'latestOffset': 12, 'triggerExecution': 12},\n",
              "  'stateOperators': [],\n",
              "  'sources': [{'description': 'KafkaV2[Subscribe[pizza-orders]]',\n",
              "    'startOffset': {'pizza-orders': {'0': 9}},\n",
              "    'endOffset': {'pizza-orders': {'0': 9}},\n",
              "    'latestOffset': {'pizza-orders': {'0': 9}},\n",
              "    'numInputRows': 0,\n",
              "    'inputRowsPerSecond': 0.0,\n",
              "    'processedRowsPerSecond': 0.0,\n",
              "    'metrics': {'avgOffsetsBehindLatest': '0.0',\n",
              "     'maxOffsetsBehindLatest': '0',\n",
              "     'minOffsetsBehindLatest': '0'}}],\n",
              "  'sink': {'description': 'org.apache.spark.sql.execution.streaming.ConsoleTable$@6f418af6',\n",
              "   'numOutputRows': 0}},\n",
              " {'id': '590d73ca-0eaa-4c3b-a9d7-47794ea5a5cd',\n",
              "  'runId': '88fc1108-a1e5-43f6-8593-a3f277ef2afe',\n",
              "  'name': None,\n",
              "  'timestamp': '2025-03-18T14:13:14.492Z',\n",
              "  'batchId': 1,\n",
              "  'numInputRows': 0,\n",
              "  'inputRowsPerSecond': 0.0,\n",
              "  'processedRowsPerSecond': 0.0,\n",
              "  'durationMs': {'latestOffset': 16, 'triggerExecution': 16},\n",
              "  'stateOperators': [],\n",
              "  'sources': [{'description': 'KafkaV2[Subscribe[pizza-orders]]',\n",
              "    'startOffset': {'pizza-orders': {'0': 9}},\n",
              "    'endOffset': {'pizza-orders': {'0': 9}},\n",
              "    'latestOffset': {'pizza-orders': {'0': 9}},\n",
              "    'numInputRows': 0,\n",
              "    'inputRowsPerSecond': 0.0,\n",
              "    'processedRowsPerSecond': 0.0,\n",
              "    'metrics': {'avgOffsetsBehindLatest': '0.0',\n",
              "     'maxOffsetsBehindLatest': '0',\n",
              "     'minOffsetsBehindLatest': '0'}}],\n",
              "  'sink': {'description': 'org.apache.spark.sql.execution.streaming.ConsoleTable$@6f418af6',\n",
              "   'numOutputRows': 0}},\n",
              " {'id': '590d73ca-0eaa-4c3b-a9d7-47794ea5a5cd',\n",
              "  'runId': '88fc1108-a1e5-43f6-8593-a3f277ef2afe',\n",
              "  'name': None,\n",
              "  'timestamp': '2025-03-18T14:13:24.497Z',\n",
              "  'batchId': 1,\n",
              "  'numInputRows': 0,\n",
              "  'inputRowsPerSecond': 0.0,\n",
              "  'processedRowsPerSecond': 0.0,\n",
              "  'durationMs': {'latestOffset': 12, 'triggerExecution': 12},\n",
              "  'stateOperators': [],\n",
              "  'sources': [{'description': 'KafkaV2[Subscribe[pizza-orders]]',\n",
              "    'startOffset': {'pizza-orders': {'0': 9}},\n",
              "    'endOffset': {'pizza-orders': {'0': 9}},\n",
              "    'latestOffset': {'pizza-orders': {'0': 9}},\n",
              "    'numInputRows': 0,\n",
              "    'inputRowsPerSecond': 0.0,\n",
              "    'processedRowsPerSecond': 0.0,\n",
              "    'metrics': {'avgOffsetsBehindLatest': '0.0',\n",
              "     'maxOffsetsBehindLatest': '0',\n",
              "     'minOffsetsBehindLatest': '0'}}],\n",
              "  'sink': {'description': 'org.apache.spark.sql.execution.streaming.ConsoleTable$@6f418af6',\n",
              "   'numOutputRows': 0}},\n",
              " {'id': '590d73ca-0eaa-4c3b-a9d7-47794ea5a5cd',\n",
              "  'runId': '88fc1108-a1e5-43f6-8593-a3f277ef2afe',\n",
              "  'name': None,\n",
              "  'timestamp': '2025-03-18T14:13:34.508Z',\n",
              "  'batchId': 1,\n",
              "  'numInputRows': 0,\n",
              "  'inputRowsPerSecond': 0.0,\n",
              "  'processedRowsPerSecond': 0.0,\n",
              "  'durationMs': {'latestOffset': 8, 'triggerExecution': 8},\n",
              "  'stateOperators': [],\n",
              "  'sources': [{'description': 'KafkaV2[Subscribe[pizza-orders]]',\n",
              "    'startOffset': {'pizza-orders': {'0': 9}},\n",
              "    'endOffset': {'pizza-orders': {'0': 9}},\n",
              "    'latestOffset': {'pizza-orders': {'0': 9}},\n",
              "    'numInputRows': 0,\n",
              "    'inputRowsPerSecond': 0.0,\n",
              "    'processedRowsPerSecond': 0.0,\n",
              "    'metrics': {'avgOffsetsBehindLatest': '0.0',\n",
              "     'maxOffsetsBehindLatest': '0',\n",
              "     'minOffsetsBehindLatest': '0'}}],\n",
              "  'sink': {'description': 'org.apache.spark.sql.execution.streaming.ConsoleTable$@6f418af6',\n",
              "   'numOutputRows': 0}},\n",
              " {'id': '590d73ca-0eaa-4c3b-a9d7-47794ea5a5cd',\n",
              "  'runId': '88fc1108-a1e5-43f6-8593-a3f277ef2afe',\n",
              "  'name': None,\n",
              "  'timestamp': '2025-03-18T14:13:36.636Z',\n",
              "  'batchId': 1,\n",
              "  'numInputRows': 1,\n",
              "  'inputRowsPerSecond': 52.631578947368425,\n",
              "  'processedRowsPerSecond': 0.7757951900698216,\n",
              "  'durationMs': {'addBatch': 699,\n",
              "   'getBatch': 1,\n",
              "   'latestOffset': 2,\n",
              "   'queryPlanning': 18,\n",
              "   'triggerExecution': 1289,\n",
              "   'walCommit': 242},\n",
              "  'stateOperators': [],\n",
              "  'sources': [{'description': 'KafkaV2[Subscribe[pizza-orders]]',\n",
              "    'startOffset': {'pizza-orders': {'0': 9}},\n",
              "    'endOffset': {'pizza-orders': {'0': 10}},\n",
              "    'latestOffset': {'pizza-orders': {'0': 10}},\n",
              "    'numInputRows': 1,\n",
              "    'inputRowsPerSecond': 52.631578947368425,\n",
              "    'processedRowsPerSecond': 0.7757951900698216,\n",
              "    'metrics': {'avgOffsetsBehindLatest': '0.0',\n",
              "     'maxOffsetsBehindLatest': '0',\n",
              "     'minOffsetsBehindLatest': '0'}}],\n",
              "  'sink': {'description': 'org.apache.spark.sql.execution.streaming.ConsoleTable$@6f418af6',\n",
              "   'numOutputRows': 1}},\n",
              " {'id': '590d73ca-0eaa-4c3b-a9d7-47794ea5a5cd',\n",
              "  'runId': '88fc1108-a1e5-43f6-8593-a3f277ef2afe',\n",
              "  'name': None,\n",
              "  'timestamp': '2025-03-18T14:13:37.925Z',\n",
              "  'batchId': 2,\n",
              "  'numInputRows': 1,\n",
              "  'inputRowsPerSecond': 0.7757951900698216,\n",
              "  'processedRowsPerSecond': 0.8176614881439084,\n",
              "  'durationMs': {'addBatch': 609,\n",
              "   'getBatch': 0,\n",
              "   'latestOffset': 6,\n",
              "   'queryPlanning': 6,\n",
              "   'triggerExecution': 1223,\n",
              "   'walCommit': 224},\n",
              "  'stateOperators': [],\n",
              "  'sources': [{'description': 'KafkaV2[Subscribe[pizza-orders]]',\n",
              "    'startOffset': {'pizza-orders': {'0': 10}},\n",
              "    'endOffset': {'pizza-orders': {'0': 11}},\n",
              "    'latestOffset': {'pizza-orders': {'0': 11}},\n",
              "    'numInputRows': 1,\n",
              "    'inputRowsPerSecond': 0.7757951900698216,\n",
              "    'processedRowsPerSecond': 0.8176614881439084,\n",
              "    'metrics': {'avgOffsetsBehindLatest': '0.0',\n",
              "     'maxOffsetsBehindLatest': '0',\n",
              "     'minOffsetsBehindLatest': '0'}}],\n",
              "  'sink': {'description': 'org.apache.spark.sql.execution.streaming.ConsoleTable$@6f418af6',\n",
              "   'numOutputRows': 1}},\n",
              " {'id': '590d73ca-0eaa-4c3b-a9d7-47794ea5a5cd',\n",
              "  'runId': '88fc1108-a1e5-43f6-8593-a3f277ef2afe',\n",
              "  'name': None,\n",
              "  'timestamp': '2025-03-18T14:13:39.635Z',\n",
              "  'batchId': 3,\n",
              "  'numInputRows': 1,\n",
              "  'inputRowsPerSecond': 83.33333333333333,\n",
              "  'processedRowsPerSecond': 0.9433962264150942,\n",
              "  'durationMs': {'addBatch': 581,\n",
              "   'getBatch': 0,\n",
              "   'latestOffset': 2,\n",
              "   'queryPlanning': 7,\n",
              "   'triggerExecution': 1060,\n",
              "   'walCommit': 250},\n",
              "  'stateOperators': [],\n",
              "  'sources': [{'description': 'KafkaV2[Subscribe[pizza-orders]]',\n",
              "    'startOffset': {'pizza-orders': {'0': 11}},\n",
              "    'endOffset': {'pizza-orders': {'0': 12}},\n",
              "    'latestOffset': {'pizza-orders': {'0': 12}},\n",
              "    'numInputRows': 1,\n",
              "    'inputRowsPerSecond': 83.33333333333333,\n",
              "    'processedRowsPerSecond': 0.9433962264150942,\n",
              "    'metrics': {'avgOffsetsBehindLatest': '0.0',\n",
              "     'maxOffsetsBehindLatest': '0',\n",
              "     'minOffsetsBehindLatest': '0'}}],\n",
              "  'sink': {'description': 'org.apache.spark.sql.execution.streaming.ConsoleTable$@6f418af6',\n",
              "   'numOutputRows': 1}},\n",
              " {'id': '590d73ca-0eaa-4c3b-a9d7-47794ea5a5cd',\n",
              "  'runId': '88fc1108-a1e5-43f6-8593-a3f277ef2afe',\n",
              "  'name': None,\n",
              "  'timestamp': '2025-03-18T14:13:41.642Z',\n",
              "  'batchId': 4,\n",
              "  'numInputRows': 1,\n",
              "  'inputRowsPerSecond': 62.5,\n",
              "  'processedRowsPerSecond': 0.8857395925597874,\n",
              "  'durationMs': {'addBatch': 583,\n",
              "   'getBatch': 0,\n",
              "   'latestOffset': 5,\n",
              "   'queryPlanning': 6,\n",
              "   'triggerExecution': 1129,\n",
              "   'walCommit': 267},\n",
              "  'stateOperators': [],\n",
              "  'sources': [{'description': 'KafkaV2[Subscribe[pizza-orders]]',\n",
              "    'startOffset': {'pizza-orders': {'0': 12}},\n",
              "    'endOffset': {'pizza-orders': {'0': 13}},\n",
              "    'latestOffset': {'pizza-orders': {'0': 13}},\n",
              "    'numInputRows': 1,\n",
              "    'inputRowsPerSecond': 62.5,\n",
              "    'processedRowsPerSecond': 0.8857395925597874,\n",
              "    'metrics': {'avgOffsetsBehindLatest': '0.0',\n",
              "     'maxOffsetsBehindLatest': '0',\n",
              "     'minOffsetsBehindLatest': '0'}}],\n",
              "  'sink': {'description': 'org.apache.spark.sql.execution.streaming.ConsoleTable$@6f418af6',\n",
              "   'numOutputRows': 1}},\n",
              " {'id': '590d73ca-0eaa-4c3b-a9d7-47794ea5a5cd',\n",
              "  'runId': '88fc1108-a1e5-43f6-8593-a3f277ef2afe',\n",
              "  'name': None,\n",
              "  'timestamp': '2025-03-18T14:13:42.772Z',\n",
              "  'batchId': 5,\n",
              "  'numInputRows': 1,\n",
              "  'inputRowsPerSecond': 0.8849557522123894,\n",
              "  'processedRowsPerSecond': 0.9337068160597572,\n",
              "  'durationMs': {'addBatch': 590,\n",
              "   'getBatch': 0,\n",
              "   'latestOffset': 3,\n",
              "   'queryPlanning': 5,\n",
              "   'triggerExecution': 1071,\n",
              "   'walCommit': 234},\n",
              "  'stateOperators': [],\n",
              "  'sources': [{'description': 'KafkaV2[Subscribe[pizza-orders]]',\n",
              "    'startOffset': {'pizza-orders': {'0': 13}},\n",
              "    'endOffset': {'pizza-orders': {'0': 14}},\n",
              "    'latestOffset': {'pizza-orders': {'0': 14}},\n",
              "    'numInputRows': 1,\n",
              "    'inputRowsPerSecond': 0.8849557522123894,\n",
              "    'processedRowsPerSecond': 0.9337068160597572,\n",
              "    'metrics': {'avgOffsetsBehindLatest': '0.0',\n",
              "     'maxOffsetsBehindLatest': '0',\n",
              "     'minOffsetsBehindLatest': '0'}}],\n",
              "  'sink': {'description': 'org.apache.spark.sql.execution.streaming.ConsoleTable$@6f418af6',\n",
              "   'numOutputRows': 1}},\n",
              " {'id': '590d73ca-0eaa-4c3b-a9d7-47794ea5a5cd',\n",
              "  'runId': '88fc1108-a1e5-43f6-8593-a3f277ef2afe',\n",
              "  'name': None,\n",
              "  'timestamp': '2025-03-18T14:13:44.655Z',\n",
              "  'batchId': 6,\n",
              "  'numInputRows': 1,\n",
              "  'inputRowsPerSecond': 66.66666666666667,\n",
              "  'processedRowsPerSecond': 0.9578544061302682,\n",
              "  'durationMs': {'addBatch': 582,\n",
              "   'getBatch': 0,\n",
              "   'latestOffset': 3,\n",
              "   'queryPlanning': 5,\n",
              "   'triggerExecution': 1044,\n",
              "   'walCommit': 225},\n",
              "  'stateOperators': [],\n",
              "  'sources': [{'description': 'KafkaV2[Subscribe[pizza-orders]]',\n",
              "    'startOffset': {'pizza-orders': {'0': 14}},\n",
              "    'endOffset': {'pizza-orders': {'0': 15}},\n",
              "    'latestOffset': {'pizza-orders': {'0': 15}},\n",
              "    'numInputRows': 1,\n",
              "    'inputRowsPerSecond': 66.66666666666667,\n",
              "    'processedRowsPerSecond': 0.9578544061302682,\n",
              "    'metrics': {'avgOffsetsBehindLatest': '0.0',\n",
              "     'maxOffsetsBehindLatest': '0',\n",
              "     'minOffsetsBehindLatest': '0'}}],\n",
              "  'sink': {'description': 'org.apache.spark.sql.execution.streaming.ConsoleTable$@6f418af6',\n",
              "   'numOutputRows': 1}},\n",
              " {'id': '590d73ca-0eaa-4c3b-a9d7-47794ea5a5cd',\n",
              "  'runId': '88fc1108-a1e5-43f6-8593-a3f277ef2afe',\n",
              "  'name': None,\n",
              "  'timestamp': '2025-03-18T14:13:45.700Z',\n",
              "  'batchId': 7,\n",
              "  'numInputRows': 1,\n",
              "  'inputRowsPerSecond': 0.9569377990430623,\n",
              "  'processedRowsPerSecond': 0.9416195856873822,\n",
              "  'durationMs': {'addBatch': 558,\n",
              "   'getBatch': 0,\n",
              "   'latestOffset': 5,\n",
              "   'queryPlanning': 4,\n",
              "   'triggerExecution': 1062,\n",
              "   'walCommit': 224},\n",
              "  'stateOperators': [],\n",
              "  'sources': [{'description': 'KafkaV2[Subscribe[pizza-orders]]',\n",
              "    'startOffset': {'pizza-orders': {'0': 15}},\n",
              "    'endOffset': {'pizza-orders': {'0': 16}},\n",
              "    'latestOffset': {'pizza-orders': {'0': 16}},\n",
              "    'numInputRows': 1,\n",
              "    'inputRowsPerSecond': 0.9569377990430623,\n",
              "    'processedRowsPerSecond': 0.9416195856873822,\n",
              "    'metrics': {'avgOffsetsBehindLatest': '0.0',\n",
              "     'maxOffsetsBehindLatest': '0',\n",
              "     'minOffsetsBehindLatest': '0'}}],\n",
              "  'sink': {'description': 'org.apache.spark.sql.execution.streaming.ConsoleTable$@6f418af6',\n",
              "   'numOutputRows': 1}},\n",
              " {'id': '590d73ca-0eaa-4c3b-a9d7-47794ea5a5cd',\n",
              "  'runId': '88fc1108-a1e5-43f6-8593-a3f277ef2afe',\n",
              "  'name': None,\n",
              "  'timestamp': '2025-03-18T14:13:46.763Z',\n",
              "  'batchId': 8,\n",
              "  'numInputRows': 1,\n",
              "  'inputRowsPerSecond': 0.9407337723424272,\n",
              "  'processedRowsPerSecond': 0.9267840593141798,\n",
              "  'durationMs': {'addBatch': 591,\n",
              "   'getBatch': 0,\n",
              "   'latestOffset': 2,\n",
              "   'queryPlanning': 18,\n",
              "   'triggerExecution': 1079,\n",
              "   'walCommit': 229},\n",
              "  'stateOperators': [],\n",
              "  'sources': [{'description': 'KafkaV2[Subscribe[pizza-orders]]',\n",
              "    'startOffset': {'pizza-orders': {'0': 16}},\n",
              "    'endOffset': {'pizza-orders': {'0': 17}},\n",
              "    'latestOffset': {'pizza-orders': {'0': 17}},\n",
              "    'numInputRows': 1,\n",
              "    'inputRowsPerSecond': 0.9407337723424272,\n",
              "    'processedRowsPerSecond': 0.9267840593141798,\n",
              "    'metrics': {'avgOffsetsBehindLatest': '0.0',\n",
              "     'maxOffsetsBehindLatest': '0',\n",
              "     'minOffsetsBehindLatest': '0'}}],\n",
              "  'sink': {'description': 'org.apache.spark.sql.execution.streaming.ConsoleTable$@6f418af6',\n",
              "   'numOutputRows': 1}},\n",
              " {'id': '590d73ca-0eaa-4c3b-a9d7-47794ea5a5cd',\n",
              "  'runId': '88fc1108-a1e5-43f6-8593-a3f277ef2afe',\n",
              "  'name': None,\n",
              "  'timestamp': '2025-03-18T14:13:48.673Z',\n",
              "  'batchId': 9,\n",
              "  'numInputRows': 1,\n",
              "  'inputRowsPerSecond': 55.55555555555556,\n",
              "  'processedRowsPerSecond': 0.9469696969696969,\n",
              "  'durationMs': {'addBatch': 549,\n",
              "   'getBatch': 5,\n",
              "   'latestOffset': 5,\n",
              "   'queryPlanning': 6,\n",
              "   'triggerExecution': 1056,\n",
              "   'walCommit': 241},\n",
              "  'stateOperators': [],\n",
              "  'sources': [{'description': 'KafkaV2[Subscribe[pizza-orders]]',\n",
              "    'startOffset': {'pizza-orders': {'0': 17}},\n",
              "    'endOffset': {'pizza-orders': {'0': 18}},\n",
              "    'latestOffset': {'pizza-orders': {'0': 18}},\n",
              "    'numInputRows': 1,\n",
              "    'inputRowsPerSecond': 55.55555555555556,\n",
              "    'processedRowsPerSecond': 0.9469696969696969,\n",
              "    'metrics': {'avgOffsetsBehindLatest': '0.0',\n",
              "     'maxOffsetsBehindLatest': '0',\n",
              "     'minOffsetsBehindLatest': '0'}}],\n",
              "  'sink': {'description': 'org.apache.spark.sql.execution.streaming.ConsoleTable$@6f418af6',\n",
              "   'numOutputRows': 1}},\n",
              " {'id': '590d73ca-0eaa-4c3b-a9d7-47794ea5a5cd',\n",
              "  'runId': '88fc1108-a1e5-43f6-8593-a3f277ef2afe',\n",
              "  'name': None,\n",
              "  'timestamp': '2025-03-18T14:13:59.731Z',\n",
              "  'batchId': 10,\n",
              "  'numInputRows': 0,\n",
              "  'inputRowsPerSecond': 0.0,\n",
              "  'processedRowsPerSecond': 0.0,\n",
              "  'durationMs': {'latestOffset': 5, 'triggerExecution': 5},\n",
              "  'stateOperators': [],\n",
              "  'sources': [{'description': 'KafkaV2[Subscribe[pizza-orders]]',\n",
              "    'startOffset': {'pizza-orders': {'0': 18}},\n",
              "    'endOffset': {'pizza-orders': {'0': 18}},\n",
              "    'latestOffset': {'pizza-orders': {'0': 18}},\n",
              "    'numInputRows': 0,\n",
              "    'inputRowsPerSecond': 0.0,\n",
              "    'processedRowsPerSecond': 0.0,\n",
              "    'metrics': {'avgOffsetsBehindLatest': '0.0',\n",
              "     'maxOffsetsBehindLatest': '0',\n",
              "     'minOffsetsBehindLatest': '0'}}],\n",
              "  'sink': {'description': 'org.apache.spark.sql.execution.streaming.ConsoleTable$@6f418af6',\n",
              "   'numOutputRows': 0}},\n",
              " {'id': '590d73ca-0eaa-4c3b-a9d7-47794ea5a5cd',\n",
              "  'runId': '88fc1108-a1e5-43f6-8593-a3f277ef2afe',\n",
              "  'name': None,\n",
              "  'timestamp': '2025-03-18T14:14:09.737Z',\n",
              "  'batchId': 10,\n",
              "  'numInputRows': 0,\n",
              "  'inputRowsPerSecond': 0.0,\n",
              "  'processedRowsPerSecond': 0.0,\n",
              "  'durationMs': {'latestOffset': 5, 'triggerExecution': 5},\n",
              "  'stateOperators': [],\n",
              "  'sources': [{'description': 'KafkaV2[Subscribe[pizza-orders]]',\n",
              "    'startOffset': {'pizza-orders': {'0': 18}},\n",
              "    'endOffset': {'pizza-orders': {'0': 18}},\n",
              "    'latestOffset': {'pizza-orders': {'0': 18}},\n",
              "    'numInputRows': 0,\n",
              "    'inputRowsPerSecond': 0.0,\n",
              "    'processedRowsPerSecond': 0.0,\n",
              "    'metrics': {'avgOffsetsBehindLatest': '0.0',\n",
              "     'maxOffsetsBehindLatest': '0',\n",
              "     'minOffsetsBehindLatest': '0'}}],\n",
              "  'sink': {'description': 'org.apache.spark.sql.execution.streaming.ConsoleTable$@6f418af6',\n",
              "   'numOutputRows': 0}},\n",
              " {'id': '590d73ca-0eaa-4c3b-a9d7-47794ea5a5cd',\n",
              "  'runId': '88fc1108-a1e5-43f6-8593-a3f277ef2afe',\n",
              "  'name': None,\n",
              "  'timestamp': '2025-03-18T14:14:19.741Z',\n",
              "  'batchId': 10,\n",
              "  'numInputRows': 0,\n",
              "  'inputRowsPerSecond': 0.0,\n",
              "  'processedRowsPerSecond': 0.0,\n",
              "  'durationMs': {'latestOffset': 4, 'triggerExecution': 4},\n",
              "  'stateOperators': [],\n",
              "  'sources': [{'description': 'KafkaV2[Subscribe[pizza-orders]]',\n",
              "    'startOffset': {'pizza-orders': {'0': 18}},\n",
              "    'endOffset': {'pizza-orders': {'0': 18}},\n",
              "    'latestOffset': {'pizza-orders': {'0': 18}},\n",
              "    'numInputRows': 0,\n",
              "    'inputRowsPerSecond': 0.0,\n",
              "    'processedRowsPerSecond': 0.0,\n",
              "    'metrics': {'avgOffsetsBehindLatest': '0.0',\n",
              "     'maxOffsetsBehindLatest': '0',\n",
              "     'minOffsetsBehindLatest': '0'}}],\n",
              "  'sink': {'description': 'org.apache.spark.sql.execution.streaming.ConsoleTable$@6f418af6',\n",
              "   'numOutputRows': 0}},\n",
              " {'id': '590d73ca-0eaa-4c3b-a9d7-47794ea5a5cd',\n",
              "  'runId': '88fc1108-a1e5-43f6-8593-a3f277ef2afe',\n",
              "  'name': None,\n",
              "  'timestamp': '2025-03-18T14:14:29.749Z',\n",
              "  'batchId': 10,\n",
              "  'numInputRows': 0,\n",
              "  'inputRowsPerSecond': 0.0,\n",
              "  'processedRowsPerSecond': 0.0,\n",
              "  'durationMs': {'latestOffset': 7, 'triggerExecution': 7},\n",
              "  'stateOperators': [],\n",
              "  'sources': [{'description': 'KafkaV2[Subscribe[pizza-orders]]',\n",
              "    'startOffset': {'pizza-orders': {'0': 18}},\n",
              "    'endOffset': {'pizza-orders': {'0': 18}},\n",
              "    'latestOffset': {'pizza-orders': {'0': 18}},\n",
              "    'numInputRows': 0,\n",
              "    'inputRowsPerSecond': 0.0,\n",
              "    'processedRowsPerSecond': 0.0,\n",
              "    'metrics': {'avgOffsetsBehindLatest': '0.0',\n",
              "     'maxOffsetsBehindLatest': '0',\n",
              "     'minOffsetsBehindLatest': '0'}}],\n",
              "  'sink': {'description': 'org.apache.spark.sql.execution.streaming.ConsoleTable$@6f418af6',\n",
              "   'numOutputRows': 0}},\n",
              " {'id': '590d73ca-0eaa-4c3b-a9d7-47794ea5a5cd',\n",
              "  'runId': '88fc1108-a1e5-43f6-8593-a3f277ef2afe',\n",
              "  'name': None,\n",
              "  'timestamp': '2025-03-18T14:14:39.754Z',\n",
              "  'batchId': 10,\n",
              "  'numInputRows': 0,\n",
              "  'inputRowsPerSecond': 0.0,\n",
              "  'processedRowsPerSecond': 0.0,\n",
              "  'durationMs': {'latestOffset': 5, 'triggerExecution': 5},\n",
              "  'stateOperators': [],\n",
              "  'sources': [{'description': 'KafkaV2[Subscribe[pizza-orders]]',\n",
              "    'startOffset': {'pizza-orders': {'0': 18}},\n",
              "    'endOffset': {'pizza-orders': {'0': 18}},\n",
              "    'latestOffset': {'pizza-orders': {'0': 18}},\n",
              "    'numInputRows': 0,\n",
              "    'inputRowsPerSecond': 0.0,\n",
              "    'processedRowsPerSecond': 0.0,\n",
              "    'metrics': {'avgOffsetsBehindLatest': '0.0',\n",
              "     'maxOffsetsBehindLatest': '0',\n",
              "     'minOffsetsBehindLatest': '0'}}],\n",
              "  'sink': {'description': 'org.apache.spark.sql.execution.streaming.ConsoleTable$@6f418af6',\n",
              "   'numOutputRows': 0}},\n",
              " {'id': '590d73ca-0eaa-4c3b-a9d7-47794ea5a5cd',\n",
              "  'runId': '88fc1108-a1e5-43f6-8593-a3f277ef2afe',\n",
              "  'name': None,\n",
              "  'timestamp': '2025-03-18T14:14:49.760Z',\n",
              "  'batchId': 10,\n",
              "  'numInputRows': 0,\n",
              "  'inputRowsPerSecond': 0.0,\n",
              "  'processedRowsPerSecond': 0.0,\n",
              "  'durationMs': {'latestOffset': 7, 'triggerExecution': 7},\n",
              "  'stateOperators': [],\n",
              "  'sources': [{'description': 'KafkaV2[Subscribe[pizza-orders]]',\n",
              "    'startOffset': {'pizza-orders': {'0': 18}},\n",
              "    'endOffset': {'pizza-orders': {'0': 18}},\n",
              "    'latestOffset': {'pizza-orders': {'0': 18}},\n",
              "    'numInputRows': 0,\n",
              "    'inputRowsPerSecond': 0.0,\n",
              "    'processedRowsPerSecond': 0.0,\n",
              "    'metrics': {'avgOffsetsBehindLatest': '0.0',\n",
              "     'maxOffsetsBehindLatest': '0',\n",
              "     'minOffsetsBehindLatest': '0'}}],\n",
              "  'sink': {'description': 'org.apache.spark.sql.execution.streaming.ConsoleTable$@6f418af6',\n",
              "   'numOutputRows': 0}},\n",
              " {'id': '590d73ca-0eaa-4c3b-a9d7-47794ea5a5cd',\n",
              "  'runId': '88fc1108-a1e5-43f6-8593-a3f277ef2afe',\n",
              "  'name': None,\n",
              "  'timestamp': '2025-03-18T14:14:59.770Z',\n",
              "  'batchId': 10,\n",
              "  'numInputRows': 0,\n",
              "  'inputRowsPerSecond': 0.0,\n",
              "  'processedRowsPerSecond': 0.0,\n",
              "  'durationMs': {'latestOffset': 8, 'triggerExecution': 8},\n",
              "  'stateOperators': [],\n",
              "  'sources': [{'description': 'KafkaV2[Subscribe[pizza-orders]]',\n",
              "    'startOffset': {'pizza-orders': {'0': 18}},\n",
              "    'endOffset': {'pizza-orders': {'0': 18}},\n",
              "    'latestOffset': {'pizza-orders': {'0': 18}},\n",
              "    'numInputRows': 0,\n",
              "    'inputRowsPerSecond': 0.0,\n",
              "    'processedRowsPerSecond': 0.0,\n",
              "    'metrics': {'avgOffsetsBehindLatest': '0.0',\n",
              "     'maxOffsetsBehindLatest': '0',\n",
              "     'minOffsetsBehindLatest': '0'}}],\n",
              "  'sink': {'description': 'org.apache.spark.sql.execution.streaming.ConsoleTable$@6f418af6',\n",
              "   'numOutputRows': 0}},\n",
              " {'id': '590d73ca-0eaa-4c3b-a9d7-47794ea5a5cd',\n",
              "  'runId': '88fc1108-a1e5-43f6-8593-a3f277ef2afe',\n",
              "  'name': None,\n",
              "  'timestamp': '2025-03-18T14:15:09.777Z',\n",
              "  'batchId': 10,\n",
              "  'numInputRows': 0,\n",
              "  'inputRowsPerSecond': 0.0,\n",
              "  'processedRowsPerSecond': 0.0,\n",
              "  'durationMs': {'latestOffset': 4, 'triggerExecution': 4},\n",
              "  'stateOperators': [],\n",
              "  'sources': [{'description': 'KafkaV2[Subscribe[pizza-orders]]',\n",
              "    'startOffset': {'pizza-orders': {'0': 18}},\n",
              "    'endOffset': {'pizza-orders': {'0': 18}},\n",
              "    'latestOffset': {'pizza-orders': {'0': 18}},\n",
              "    'numInputRows': 0,\n",
              "    'inputRowsPerSecond': 0.0,\n",
              "    'processedRowsPerSecond': 0.0,\n",
              "    'metrics': {'avgOffsetsBehindLatest': '0.0',\n",
              "     'maxOffsetsBehindLatest': '0',\n",
              "     'minOffsetsBehindLatest': '0'}}],\n",
              "  'sink': {'description': 'org.apache.spark.sql.execution.streaming.ConsoleTable$@6f418af6',\n",
              "   'numOutputRows': 0}},\n",
              " {'id': '590d73ca-0eaa-4c3b-a9d7-47794ea5a5cd',\n",
              "  'runId': '88fc1108-a1e5-43f6-8593-a3f277ef2afe',\n",
              "  'name': None,\n",
              "  'timestamp': '2025-03-18T14:15:19.789Z',\n",
              "  'batchId': 10,\n",
              "  'numInputRows': 0,\n",
              "  'inputRowsPerSecond': 0.0,\n",
              "  'processedRowsPerSecond': 0.0,\n",
              "  'durationMs': {'latestOffset': 2, 'triggerExecution': 2},\n",
              "  'stateOperators': [],\n",
              "  'sources': [{'description': 'KafkaV2[Subscribe[pizza-orders]]',\n",
              "    'startOffset': {'pizza-orders': {'0': 18}},\n",
              "    'endOffset': {'pizza-orders': {'0': 18}},\n",
              "    'latestOffset': {'pizza-orders': {'0': 18}},\n",
              "    'numInputRows': 0,\n",
              "    'inputRowsPerSecond': 0.0,\n",
              "    'processedRowsPerSecond': 0.0,\n",
              "    'metrics': {'avgOffsetsBehindLatest': '0.0',\n",
              "     'maxOffsetsBehindLatest': '0',\n",
              "     'minOffsetsBehindLatest': '0'}}],\n",
              "  'sink': {'description': 'org.apache.spark.sql.execution.streaming.ConsoleTable$@6f418af6',\n",
              "   'numOutputRows': 0}},\n",
              " {'id': '590d73ca-0eaa-4c3b-a9d7-47794ea5a5cd',\n",
              "  'runId': '88fc1108-a1e5-43f6-8593-a3f277ef2afe',\n",
              "  'name': None,\n",
              "  'timestamp': '2025-03-18T14:15:25.471Z',\n",
              "  'batchId': 10,\n",
              "  'numInputRows': 1,\n",
              "  'inputRowsPerSecond': 52.631578947368425,\n",
              "  'processedRowsPerSecond': 0.89126559714795,\n",
              "  'durationMs': {'addBatch': 587,\n",
              "   'getBatch': 0,\n",
              "   'latestOffset': 2,\n",
              "   'queryPlanning': 4,\n",
              "   'triggerExecution': 1122,\n",
              "   'walCommit': 268},\n",
              "  'stateOperators': [],\n",
              "  'sources': [{'description': 'KafkaV2[Subscribe[pizza-orders]]',\n",
              "    'startOffset': {'pizza-orders': {'0': 18}},\n",
              "    'endOffset': {'pizza-orders': {'0': 19}},\n",
              "    'latestOffset': {'pizza-orders': {'0': 19}},\n",
              "    'numInputRows': 1,\n",
              "    'inputRowsPerSecond': 52.631578947368425,\n",
              "    'processedRowsPerSecond': 0.89126559714795,\n",
              "    'metrics': {'avgOffsetsBehindLatest': '0.0',\n",
              "     'maxOffsetsBehindLatest': '0',\n",
              "     'minOffsetsBehindLatest': '0'}}],\n",
              "  'sink': {'description': 'org.apache.spark.sql.execution.streaming.ConsoleTable$@6f418af6',\n",
              "   'numOutputRows': 1}},\n",
              " {'id': '590d73ca-0eaa-4c3b-a9d7-47794ea5a5cd',\n",
              "  'runId': '88fc1108-a1e5-43f6-8593-a3f277ef2afe',\n",
              "  'name': None,\n",
              "  'timestamp': '2025-03-18T14:15:26.593Z',\n",
              "  'batchId': 11,\n",
              "  'numInputRows': 1,\n",
              "  'inputRowsPerSecond': 0.89126559714795,\n",
              "  'processedRowsPerSecond': 1.0141987829614605,\n",
              "  'durationMs': {'addBatch': 553,\n",
              "   'getBatch': 0,\n",
              "   'latestOffset': 12,\n",
              "   'queryPlanning': 5,\n",
              "   'triggerExecution': 986,\n",
              "   'walCommit': 241},\n",
              "  'stateOperators': [],\n",
              "  'sources': [{'description': 'KafkaV2[Subscribe[pizza-orders]]',\n",
              "    'startOffset': {'pizza-orders': {'0': 19}},\n",
              "    'endOffset': {'pizza-orders': {'0': 20}},\n",
              "    'latestOffset': {'pizza-orders': {'0': 20}},\n",
              "    'numInputRows': 1,\n",
              "    'inputRowsPerSecond': 0.89126559714795,\n",
              "    'processedRowsPerSecond': 1.0141987829614605,\n",
              "    'metrics': {'avgOffsetsBehindLatest': '0.0',\n",
              "     'maxOffsetsBehindLatest': '0',\n",
              "     'minOffsetsBehindLatest': '0'}}],\n",
              "  'sink': {'description': 'org.apache.spark.sql.execution.streaming.ConsoleTable$@6f418af6',\n",
              "   'numOutputRows': 1}},\n",
              " {'id': '590d73ca-0eaa-4c3b-a9d7-47794ea5a5cd',\n",
              "  'runId': '88fc1108-a1e5-43f6-8593-a3f277ef2afe',\n",
              "  'name': None,\n",
              "  'timestamp': '2025-03-18T14:15:28.481Z',\n",
              "  'batchId': 12,\n",
              "  'numInputRows': 1,\n",
              "  'inputRowsPerSecond': 50.0,\n",
              "  'processedRowsPerSecond': 1.0471204188481675,\n",
              "  'durationMs': {'addBatch': 548,\n",
              "   'getBatch': 0,\n",
              "   'latestOffset': 8,\n",
              "   'queryPlanning': 4,\n",
              "   'triggerExecution': 955,\n",
              "   'walCommit': 194},\n",
              "  'stateOperators': [],\n",
              "  'sources': [{'description': 'KafkaV2[Subscribe[pizza-orders]]',\n",
              "    'startOffset': {'pizza-orders': {'0': 20}},\n",
              "    'endOffset': {'pizza-orders': {'0': 21}},\n",
              "    'latestOffset': {'pizza-orders': {'0': 21}},\n",
              "    'numInputRows': 1,\n",
              "    'inputRowsPerSecond': 50.0,\n",
              "    'processedRowsPerSecond': 1.0471204188481675,\n",
              "    'metrics': {'avgOffsetsBehindLatest': '0.0',\n",
              "     'maxOffsetsBehindLatest': '0',\n",
              "     'minOffsetsBehindLatest': '0'}}],\n",
              "  'sink': {'description': 'org.apache.spark.sql.execution.streaming.ConsoleTable$@6f418af6',\n",
              "   'numOutputRows': 1}},\n",
              " {'id': '590d73ca-0eaa-4c3b-a9d7-47794ea5a5cd',\n",
              "  'runId': '88fc1108-a1e5-43f6-8593-a3f277ef2afe',\n",
              "  'name': None,\n",
              "  'timestamp': '2025-03-18T14:15:29.472Z',\n",
              "  'batchId': 13,\n",
              "  'numInputRows': 1,\n",
              "  'inputRowsPerSecond': 55.55555555555556,\n",
              "  'processedRowsPerSecond': 0.9442870632672333,\n",
              "  'durationMs': {'addBatch': 553,\n",
              "   'getBatch': 0,\n",
              "   'latestOffset': 6,\n",
              "   'queryPlanning': 6,\n",
              "   'triggerExecution': 1059,\n",
              "   'walCommit': 306},\n",
              "  'stateOperators': [],\n",
              "  'sources': [{'description': 'KafkaV2[Subscribe[pizza-orders]]',\n",
              "    'startOffset': {'pizza-orders': {'0': 21}},\n",
              "    'endOffset': {'pizza-orders': {'0': 22}},\n",
              "    'latestOffset': {'pizza-orders': {'0': 22}},\n",
              "    'numInputRows': 1,\n",
              "    'inputRowsPerSecond': 55.55555555555556,\n",
              "    'processedRowsPerSecond': 0.9442870632672333,\n",
              "    'metrics': {'avgOffsetsBehindLatest': '0.0',\n",
              "     'maxOffsetsBehindLatest': '0',\n",
              "     'minOffsetsBehindLatest': '0'}}],\n",
              "  'sink': {'description': 'org.apache.spark.sql.execution.streaming.ConsoleTable$@6f418af6',\n",
              "   'numOutputRows': 1}},\n",
              " {'id': '590d73ca-0eaa-4c3b-a9d7-47794ea5a5cd',\n",
              "  'runId': '88fc1108-a1e5-43f6-8593-a3f277ef2afe',\n",
              "  'name': None,\n",
              "  'timestamp': '2025-03-18T14:15:31.475Z',\n",
              "  'batchId': 14,\n",
              "  'numInputRows': 1,\n",
              "  'inputRowsPerSecond': 66.66666666666667,\n",
              "  'processedRowsPerSecond': 0.998003992015968,\n",
              "  'durationMs': {'addBatch': 556,\n",
              "   'getBatch': 0,\n",
              "   'latestOffset': 9,\n",
              "   'queryPlanning': 4,\n",
              "   'triggerExecution': 1002,\n",
              "   'walCommit': 218},\n",
              "  'stateOperators': [],\n",
              "  'sources': [{'description': 'KafkaV2[Subscribe[pizza-orders]]',\n",
              "    'startOffset': {'pizza-orders': {'0': 22}},\n",
              "    'endOffset': {'pizza-orders': {'0': 23}},\n",
              "    'latestOffset': {'pizza-orders': {'0': 23}},\n",
              "    'numInputRows': 1,\n",
              "    'inputRowsPerSecond': 66.66666666666667,\n",
              "    'processedRowsPerSecond': 0.998003992015968,\n",
              "    'metrics': {'avgOffsetsBehindLatest': '0.0',\n",
              "     'maxOffsetsBehindLatest': '0',\n",
              "     'minOffsetsBehindLatest': '0'}}],\n",
              "  'sink': {'description': 'org.apache.spark.sql.execution.streaming.ConsoleTable$@6f418af6',\n",
              "   'numOutputRows': 1}},\n",
              " {'id': '590d73ca-0eaa-4c3b-a9d7-47794ea5a5cd',\n",
              "  'runId': '88fc1108-a1e5-43f6-8593-a3f277ef2afe',\n",
              "  'name': None,\n",
              "  'timestamp': '2025-03-18T14:15:32.477Z',\n",
              "  'batchId': 15,\n",
              "  'numInputRows': 1,\n",
              "  'inputRowsPerSecond': 0.998003992015968,\n",
              "  'processedRowsPerSecond': 1.050420168067227,\n",
              "  'durationMs': {'addBatch': 547,\n",
              "   'getBatch': 0,\n",
              "   'latestOffset': 11,\n",
              "   'queryPlanning': 3,\n",
              "   'triggerExecution': 952,\n",
              "   'walCommit': 214},\n",
              "  'stateOperators': [],\n",
              "  'sources': [{'description': 'KafkaV2[Subscribe[pizza-orders]]',\n",
              "    'startOffset': {'pizza-orders': {'0': 23}},\n",
              "    'endOffset': {'pizza-orders': {'0': 24}},\n",
              "    'latestOffset': {'pizza-orders': {'0': 24}},\n",
              "    'numInputRows': 1,\n",
              "    'inputRowsPerSecond': 0.998003992015968,\n",
              "    'processedRowsPerSecond': 1.050420168067227,\n",
              "    'metrics': {'avgOffsetsBehindLatest': '0.0',\n",
              "     'maxOffsetsBehindLatest': '0',\n",
              "     'minOffsetsBehindLatest': '0'}}],\n",
              "  'sink': {'description': 'org.apache.spark.sql.execution.streaming.ConsoleTable$@6f418af6',\n",
              "   'numOutputRows': 1}},\n",
              " {'id': '590d73ca-0eaa-4c3b-a9d7-47794ea5a5cd',\n",
              "  'runId': '88fc1108-a1e5-43f6-8593-a3f277ef2afe',\n",
              "  'name': None,\n",
              "  'timestamp': '2025-03-18T14:15:33.476Z',\n",
              "  'batchId': 16,\n",
              "  'numInputRows': 1,\n",
              "  'inputRowsPerSecond': 62.5,\n",
              "  'processedRowsPerSecond': 1.050420168067227,\n",
              "  'durationMs': {'addBatch': 553,\n",
              "   'getBatch': 0,\n",
              "   'latestOffset': 4,\n",
              "   'queryPlanning': 5,\n",
              "   'triggerExecution': 952,\n",
              "   'walCommit': 211},\n",
              "  'stateOperators': [],\n",
              "  'sources': [{'description': 'KafkaV2[Subscribe[pizza-orders]]',\n",
              "    'startOffset': {'pizza-orders': {'0': 24}},\n",
              "    'endOffset': {'pizza-orders': {'0': 25}},\n",
              "    'latestOffset': {'pizza-orders': {'0': 25}},\n",
              "    'numInputRows': 1,\n",
              "    'inputRowsPerSecond': 62.5,\n",
              "    'processedRowsPerSecond': 1.050420168067227,\n",
              "    'metrics': {'avgOffsetsBehindLatest': '0.0',\n",
              "     'maxOffsetsBehindLatest': '0',\n",
              "     'minOffsetsBehindLatest': '0'}}],\n",
              "  'sink': {'description': 'org.apache.spark.sql.execution.streaming.ConsoleTable$@6f418af6',\n",
              "   'numOutputRows': 1}},\n",
              " {'id': '590d73ca-0eaa-4c3b-a9d7-47794ea5a5cd',\n",
              "  'runId': '88fc1108-a1e5-43f6-8593-a3f277ef2afe',\n",
              "  'name': None,\n",
              "  'timestamp': '2025-03-18T14:15:34.490Z',\n",
              "  'batchId': 17,\n",
              "  'numInputRows': 1,\n",
              "  'inputRowsPerSecond': 62.5,\n",
              "  'processedRowsPerSecond': 1.0,\n",
              "  'durationMs': {'addBatch': 557,\n",
              "   'getBatch': 0,\n",
              "   'latestOffset': 4,\n",
              "   'queryPlanning': 3,\n",
              "   'triggerExecution': 1000,\n",
              "   'walCommit': 230},\n",
              "  'stateOperators': [],\n",
              "  'sources': [{'description': 'KafkaV2[Subscribe[pizza-orders]]',\n",
              "    'startOffset': {'pizza-orders': {'0': 25}},\n",
              "    'endOffset': {'pizza-orders': {'0': 26}},\n",
              "    'latestOffset': {'pizza-orders': {'0': 26}},\n",
              "    'numInputRows': 1,\n",
              "    'inputRowsPerSecond': 62.5,\n",
              "    'processedRowsPerSecond': 1.0,\n",
              "    'metrics': {'avgOffsetsBehindLatest': '0.0',\n",
              "     'maxOffsetsBehindLatest': '0',\n",
              "     'minOffsetsBehindLatest': '0'}}],\n",
              "  'sink': {'description': 'org.apache.spark.sql.execution.streaming.ConsoleTable$@6f418af6',\n",
              "   'numOutputRows': 1}},\n",
              " {'id': '590d73ca-0eaa-4c3b-a9d7-47794ea5a5cd',\n",
              "  'runId': '88fc1108-a1e5-43f6-8593-a3f277ef2afe',\n",
              "  'name': None,\n",
              "  'timestamp': '2025-03-18T14:15:35.490Z',\n",
              "  'batchId': 18,\n",
              "  'numInputRows': 1,\n",
              "  'inputRowsPerSecond': 1.0,\n",
              "  'processedRowsPerSecond': 1.0559662090813096,\n",
              "  'durationMs': {'addBatch': 544,\n",
              "   'getBatch': 0,\n",
              "   'latestOffset': 5,\n",
              "   'queryPlanning': 4,\n",
              "   'triggerExecution': 947,\n",
              "   'walCommit': 208},\n",
              "  'stateOperators': [],\n",
              "  'sources': [{'description': 'KafkaV2[Subscribe[pizza-orders]]',\n",
              "    'startOffset': {'pizza-orders': {'0': 26}},\n",
              "    'endOffset': {'pizza-orders': {'0': 27}},\n",
              "    'latestOffset': {'pizza-orders': {'0': 27}},\n",
              "    'numInputRows': 1,\n",
              "    'inputRowsPerSecond': 1.0,\n",
              "    'processedRowsPerSecond': 1.0559662090813096,\n",
              "    'metrics': {'avgOffsetsBehindLatest': '0.0',\n",
              "     'maxOffsetsBehindLatest': '0',\n",
              "     'minOffsetsBehindLatest': '0'}}],\n",
              "  'sink': {'description': 'org.apache.spark.sql.execution.streaming.ConsoleTable$@6f418af6',\n",
              "   'numOutputRows': 1}}]"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------\n",
            "Batch: 19\n",
            "-------------------------------------------\n",
            "+--------------------+--------------------+\n",
            "|           timestamp|               value|\n",
            "+--------------------+--------------------+\n",
            "|2025-03-18 22:15:...|{4298 Schroeder C...|\n",
            "+--------------------+--------------------+\n",
            "\n",
            "-------------------------------------------\n",
            "Batch: 19\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "Batch: 19\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "Batch: 19\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "Batch: 19\n",
            "-------------------------------------------\n",
            "+--------------------+--------------------+\n",
            "|           timestamp|               value|\n",
            "+--------------------+--------------------+\n",
            "|2025-03-18 22:15:...|{4298 Schroeder C...|\n",
            "+--------------------+--------------------+\n",
            "\n",
            "-------------------------------------------\n",
            "Batch: 19\n",
            "-------------------------------------------\n",
            "+--------------------+--------------------+\n",
            "|           timestamp|               value|\n",
            "+--------------------+--------------------+\n",
            "|2025-03-18 22:15:...|{4298 Schroeder C...|\n",
            "+--------------------+--------------------+\n",
            "\n",
            "+--------------------+--------------------+\n",
            "|           timestamp|               value|\n",
            "+--------------------+--------------------+\n",
            "|2025-03-18 22:15:...|{4298 Schroeder C...|\n",
            "+--------------------+--------------------+\n",
            "\n",
            "+--------------------+--------------------+\n",
            "|           timestamp|               value|\n",
            "+--------------------+--------------------+\n",
            "|2025-03-18 22:15:...|{4298 Schroeder C...|\n",
            "+--------------------+--------------------+\n",
            "\n",
            "+--------------------+--------------------+\n",
            "|           timestamp|               value|\n",
            "+--------------------+--------------------+\n",
            "|2025-03-18 22:15:...|{4298 Schroeder C...|\n",
            "+--------------------+--------------------+\n",
            "\n",
            "-------------------------------------------\n",
            "Batch: 20\n",
            "-------------------------------------------\n",
            "+--------------------+--------------------+\n",
            "|           timestamp|               value|\n",
            "+--------------------+--------------------+\n",
            "|2025-03-18 22:15:...|{0346 Joyce Pine\\...|\n",
            "+--------------------+--------------------+\n",
            "\n",
            "-------------------------------------------\n",
            "Batch: 20\n",
            "-------------------------------------------\n",
            "+--------------------+--------------------+\n",
            "|           timestamp|               value|\n",
            "+--------------------+--------------------+\n",
            "|2025-03-18 22:15:...|{0346 Joyce Pine\\...|\n",
            "+--------------------+--------------------+\n",
            "\n",
            "-------------------------------------------\n",
            "Batch: 20\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "Batch: 20\n",
            "-------------------------------------------\n",
            "+--------------------+--------------------+\n",
            "|           timestamp|               value|\n",
            "+--------------------+--------------------+\n",
            "|2025-03-18 22:15:...|{0346 Joyce Pine\\...|\n",
            "+--------------------+--------------------+\n",
            "\n",
            "+--------------------+--------------------+\n",
            "|           timestamp|               value|\n",
            "+--------------------+--------------------+\n",
            "|2025-03-18 22:15:...|{0346 Joyce Pine\\...|\n",
            "+--------------------+--------------------+\n",
            "\n",
            "-------------------------------------------\n",
            "Batch: 20\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "Batch: 20\n",
            "-------------------------------------------\n",
            "+--------------------+--------------------+\n",
            "|           timestamp|               value|\n",
            "+--------------------+--------------------+\n",
            "|2025-03-18 22:15:...|{0346 Joyce Pine\\...|\n",
            "+--------------------+--------------------+\n",
            "\n",
            "+--------------------+--------------------+\n",
            "|           timestamp|               value|\n",
            "+--------------------+--------------------+\n",
            "|2025-03-18 22:15:...|{0346 Joyce Pine\\...|\n",
            "+--------------------+--------------------+\n",
            "\n",
            "-------------------------------------------\n",
            "Batch: 21\n",
            "-------------------------------------------\n",
            "+--------------------+--------------------+\n",
            "|           timestamp|               value|\n",
            "+--------------------+--------------------+\n",
            "|2025-03-18 22:15:...|{0603 Brandi Path...|\n",
            "+--------------------+--------------------+\n",
            "\n",
            "-------------------------------------------\n",
            "Batch: 21\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "Batch: 21\n",
            "-------------------------------------------\n",
            "+--------------------+--------------------+\n",
            "|           timestamp|               value|\n",
            "+--------------------+--------------------+\n",
            "|2025-03-18 22:15:...|{0603 Brandi Path...|\n",
            "+--------------------+--------------------+\n",
            "\n",
            "+--------------------+--------------------+\n",
            "|           timestamp|               value|\n",
            "+--------------------+--------------------+\n",
            "|2025-03-18 22:15:...|{0603 Brandi Path...|\n",
            "+--------------------+--------------------+\n",
            "\n",
            "-------------------------------------------\n",
            "Batch: 21\n",
            "-------------------------------------------\n",
            "+--------------------+--------------------+\n",
            "|           timestamp|               value|\n",
            "+--------------------+--------------------+\n",
            "|2025-03-18 22:15:...|{0603 Brandi Path...|\n",
            "+--------------------+--------------------+\n",
            "\n",
            "-------------------------------------------\n",
            "Batch: 21\n",
            "-------------------------------------------\n",
            "+--------------------+--------------------+\n",
            "|           timestamp|               value|\n",
            "+--------------------+--------------------+\n",
            "|2025-03-18 22:15:...|{0603 Brandi Path...|\n",
            "+--------------------+--------------------+\n",
            "\n",
            "-------------------------------------------\n",
            "Batch: 21\n",
            "-------------------------------------------\n",
            "+--------------------+--------------------+\n",
            "|           timestamp|               value|\n",
            "+--------------------+--------------------+\n",
            "|2025-03-18 22:15:...|{0603 Brandi Path...|\n",
            "+--------------------+--------------------+\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------\n",
            "Batch: 22\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "Batch: 22\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "Batch: 22\n",
            "-------------------------------------------\n",
            "+--------------------+--------------------+\n",
            "|           timestamp|               value|\n",
            "+--------------------+--------------------+\n",
            "|2025-03-18 22:15:...|{94556 Chaney Cam...|\n",
            "+--------------------+--------------------+\n",
            "\n",
            "+--------------------+--------------------+\n",
            "|           timestamp|               value|\n",
            "+--------------------+--------------------+\n",
            "|2025-03-18 22:15:...|{94556 Chaney Cam...|\n",
            "+--------------------+--------------------+\n",
            "\n",
            "+--------------------+--------------------+\n",
            "|           timestamp|               value|\n",
            "+--------------------+--------------------+\n",
            "|2025-03-18 22:15:...|{94556 Chaney Cam...|\n",
            "+--------------------+--------------------+\n",
            "\n",
            "-------------------------------------------\n",
            "Batch: 22\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "Batch: 22\n",
            "-------------------------------------------\n",
            "+--------------------+--------------------+\n",
            "|           timestamp|               value|\n",
            "+--------------------+--------------------+\n",
            "|2025-03-18 22:15:...|{94556 Chaney Cam...|\n",
            "+--------------------+--------------------+\n",
            "\n",
            "-------------------------------------------\n",
            "Batch: 22\n",
            "-------------------------------------------\n",
            "+--------------------+--------------------+\n",
            "|           timestamp|               value|\n",
            "+--------------------+--------------------+\n",
            "|2025-03-18 22:15:...|{94556 Chaney Cam...|\n",
            "+--------------------+--------------------+\n",
            "\n",
            "+--------------------+--------------------+\n",
            "|           timestamp|               value|\n",
            "+--------------------+--------------------+\n",
            "|2025-03-18 22:15:...|{94556 Chaney Cam...|\n",
            "+--------------------+--------------------+\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------\n",
            "Batch: 23\n",
            "-------------------------------------------\n",
            "+--------------------+--------------------+\n",
            "|           timestamp|               value|\n",
            "+--------------------+--------------------+\n",
            "|2025-03-18 22:15:...|{3903 Jose Fords\\...|\n",
            "+--------------------+--------------------+\n",
            "\n",
            "-------------------------------------------\n",
            "Batch: 23\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "Batch: 23\n",
            "-------------------------------------------\n",
            "+--------------------+--------------------+\n",
            "|           timestamp|               value|\n",
            "+--------------------+--------------------+\n",
            "|2025-03-18 22:15:...|{3903 Jose Fords\\...|\n",
            "+--------------------+--------------------+\n",
            "\n",
            "+--------------------+--------------------+\n",
            "|           timestamp|               value|\n",
            "+--------------------+--------------------+\n",
            "|2025-03-18 22:15:...|{3903 Jose Fords\\...|\n",
            "+--------------------+--------------------+\n",
            "\n",
            "-------------------------------------------\n",
            "Batch: 23\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "Batch: 23\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "Batch: 23\n",
            "-------------------------------------------\n",
            "+--------------------+--------------------+\n",
            "|           timestamp|               value|\n",
            "+--------------------+--------------------+\n",
            "|2025-03-18 22:15:...|{3903 Jose Fords\\...|\n",
            "+--------------------+--------------------+\n",
            "\n",
            "+--------------------+--------------------+\n",
            "|           timestamp|               value|\n",
            "+--------------------+--------------------+\n",
            "|2025-03-18 22:15:...|{3903 Jose Fords\\...|\n",
            "+--------------------+--------------------+\n",
            "\n",
            "+--------------------+--------------------+\n",
            "|           timestamp|               value|\n",
            "+--------------------+--------------------+\n",
            "|2025-03-18 22:15:...|{3903 Jose Fords\\...|\n",
            "+--------------------+--------------------+\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------\n",
            "Batch: 24\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "Batch: 24\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "Batch: 24\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "Batch: 24\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "Batch: 24\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "Batch: 24\n",
            "-------------------------------------------\n",
            "+--------------------+--------------------+\n",
            "|           timestamp|               value|\n",
            "+--------------------+--------------------+\n",
            "|2025-03-18 22:15:...|{06867 Sean Sprin...|\n",
            "+--------------------+--------------------+\n",
            "\n",
            "+--------------------+--------------------+\n",
            "|           timestamp|               value|\n",
            "+--------------------+--------------------+\n",
            "|2025-03-18 22:15:...|{06867 Sean Sprin...|\n",
            "+--------------------+--------------------+\n",
            "\n",
            "+--------------------+--------------------+\n",
            "|           timestamp|               value|\n",
            "+--------------------+--------------------+\n",
            "|2025-03-18 22:15:...|{06867 Sean Sprin...|\n",
            "+--------------------+--------------------+\n",
            "\n",
            "+--------------------+--------------------+\n",
            "|           timestamp|               value|\n",
            "+--------------------+--------------------+\n",
            "|2025-03-18 22:15:...|{06867 Sean Sprin...|\n",
            "+--------------------+--------------------+\n",
            "\n",
            "+--------------------+--------------------+\n",
            "|           timestamp|               value|\n",
            "+--------------------+--------------------+\n",
            "|2025-03-18 22:15:...|{06867 Sean Sprin...|\n",
            "+--------------------+--------------------+\n",
            "\n",
            "+--------------------+--------------------+\n",
            "|           timestamp|               value|\n",
            "+--------------------+--------------------+\n",
            "|2025-03-18 22:15:...|{06867 Sean Sprin...|\n",
            "+--------------------+--------------------+\n",
            "\n",
            "-------------------------------------------\n",
            "Batch: 25\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "Batch: 25\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "Batch: 25\n",
            "-------------------------------------------\n",
            "+--------------------+--------------------+\n",
            "|           timestamp|               value|\n",
            "+--------------------+--------------------+\n",
            "|2025-03-18 22:15:...|{5781 John Fords\\...|\n",
            "+--------------------+--------------------+\n",
            "\n",
            "+--------------------+--------------------+\n",
            "|           timestamp|               value|\n",
            "+--------------------+--------------------+\n",
            "|2025-03-18 22:15:...|{5781 John Fords\\...|\n",
            "+--------------------+--------------------+\n",
            "\n",
            "+--------------------+--------------------+\n",
            "|           timestamp|               value|\n",
            "+--------------------+--------------------+\n",
            "|2025-03-18 22:15:...|{5781 John Fords\\...|\n",
            "+--------------------+--------------------+\n",
            "\n",
            "-------------------------------------------\n",
            "Batch: 25\n",
            "-------------------------------------------\n",
            "+--------------------+--------------------+\n",
            "|           timestamp|               value|\n",
            "+--------------------+--------------------+\n",
            "|2025-03-18 22:15:...|{5781 John Fords\\...|\n",
            "+--------------------+--------------------+\n",
            "\n",
            "-------------------------------------------\n",
            "Batch: 25\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "Batch: 25\n",
            "-------------------------------------------\n",
            "+--------------------+--------------------+\n",
            "|           timestamp|               value|\n",
            "+--------------------+--------------------+\n",
            "|2025-03-18 22:15:...|{5781 John Fords\\...|\n",
            "+--------------------+--------------------+\n",
            "\n",
            "+--------------------+--------------------+\n",
            "|           timestamp|               value|\n",
            "+--------------------+--------------------+\n",
            "|2025-03-18 22:15:...|{5781 John Fords\\...|\n",
            "+--------------------+--------------------+\n",
            "\n",
            "-------------------------------------------\n",
            "Batch: 26\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "Batch: 26\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "Batch: 26\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "Batch: 26\n",
            "-------------------------------------------\n",
            "+--------------------+--------------------+\n",
            "|           timestamp|               value|\n",
            "+--------------------+--------------------+\n",
            "|2025-03-18 22:16:...|{42486 Kelly Traf...|\n",
            "+--------------------+--------------------+\n",
            "\n",
            "+--------------------+--------------------+\n",
            "|           timestamp|               value|\n",
            "+--------------------+--------------------+\n",
            "|2025-03-18 22:16:...|{42486 Kelly Traf...|\n",
            "+--------------------+--------------------+\n",
            "\n",
            "+--------------------+--------------------+\n",
            "|           timestamp|               value|\n",
            "+--------------------+--------------------+\n",
            "|2025-03-18 22:16:...|{42486 Kelly Traf...|\n",
            "+--------------------+--------------------+\n",
            "\n",
            "+--------------------+--------------------+\n",
            "|           timestamp|               value|\n",
            "+--------------------+--------------------+\n",
            "|2025-03-18 22:16:...|{42486 Kelly Traf...|\n",
            "+--------------------+--------------------+\n",
            "\n",
            "-------------------------------------------\n",
            "Batch: 26\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "Batch: 26\n",
            "-------------------------------------------\n",
            "+--------------------+--------------------+\n",
            "|           timestamp|               value|\n",
            "+--------------------+--------------------+\n",
            "|2025-03-18 22:16:...|{42486 Kelly Traf...|\n",
            "+--------------------+--------------------+\n",
            "\n",
            "+--------------------+--------------------+\n",
            "|           timestamp|               value|\n",
            "+--------------------+--------------------+\n",
            "|2025-03-18 22:16:...|{42486 Kelly Traf...|\n",
            "+--------------------+--------------------+\n",
            "\n",
            "-------------------------------------------\n",
            "Batch: 27\n",
            "-------------------------------------------\n",
            "+--------------------+--------------------+\n",
            "|           timestamp|               value|\n",
            "+--------------------+--------------------+\n",
            "|2025-03-18 22:16:...|{37881 Clayton Co...|\n",
            "+--------------------+--------------------+\n",
            "\n",
            "-------------------------------------------\n",
            "Batch: 27\n",
            "-------------------------------------------\n",
            "+--------------------+--------------------+\n",
            "|           timestamp|               value|\n",
            "+--------------------+--------------------+\n",
            "|2025-03-18 22:16:...|{37881 Clayton Co...|\n",
            "+--------------------+--------------------+\n",
            "\n",
            "-------------------------------------------\n",
            "Batch: 27\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "Batch: 27\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "Batch: 27\n",
            "-------------------------------------------\n",
            "+--------------------+--------------------+\n",
            "|           timestamp|               value|\n",
            "+--------------------+--------------------+\n",
            "|2025-03-18 22:16:...|{37881 Clayton Co...|\n",
            "+--------------------+--------------------+\n",
            "\n",
            "+--------------------+--------------------+\n",
            "|           timestamp|               value|\n",
            "+--------------------+--------------------+\n",
            "|2025-03-18 22:16:...|{37881 Clayton Co...|\n",
            "+--------------------+--------------------+\n",
            "\n",
            "+--------------------+--------------------+\n",
            "|           timestamp|               value|\n",
            "+--------------------+--------------------+\n",
            "|2025-03-18 22:16:...|{37881 Clayton Co...|\n",
            "+--------------------+--------------------+\n",
            "\n",
            "-------------------------------------------\n",
            "Batch: 27\n",
            "-------------------------------------------\n",
            "+--------------------+--------------------+\n",
            "|           timestamp|               value|\n",
            "+--------------------+--------------------+\n",
            "|2025-03-18 22:16:...|{37881 Clayton Co...|\n",
            "+--------------------+--------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "query.recentProgress"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### In the next few cells, we will provide a complete example of counting the number of pizza shops with orders, as the orders stream in."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# First check if any streams are active\n",
        "spark.streams.active"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# If there are any active streams, stop them\n",
        "for q in spark.streams.active:\n",
        "    print(f\"Stopping query: {q.name}\")\n",
        "    q.stop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Complete example with counting\n",
        "pizza_df = spark.readStream.format('kafka')\\\n",
        "    .options(**options)\\\n",
        "    .load()\n",
        "\n",
        "parsed_df = pizza_df.select(\"timestamp\", from_json(col(\"value\").cast(\"string\"), order_schema).alias(\"value\")) #.groupBy(\"value.shop\").count()\n",
        "\n",
        "shop_counts = parsed_df.groupBy(\"value.shop\").count()\n",
        "\n",
        "# outputMode(\"complete\") rewrites all aggregated results every trigger — good for full snapshots.\n",
        "# outputMode(\"update\") - only updated rows are written\n",
        "query = shop_counts \\\n",
        "    .writeStream \\\n",
        "    .outputMode(\"complete\") \\\n",
        "    .format(\"console\") \\\n",
        "    .start()\n",
        "\n",
        "query.awaitTermination()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "query.stop()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You have come to the end of this exercise.\n",
        "\n",
        "To delete the Kafka topic `pizza-orders`, use the command below in your terminal:\n",
        "\n",
        "`./kafka-topics.sh --delete --topic pizza-orders --bootstrap-server localhost:9092`\n",
        "\n",
        "To exit Kafka in your terminal, type `exit`."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "kafka",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
